{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 b\n",
      "2 c\n"
     ]
    }
   ],
   "source": [
    "a = {\n",
    "    'a':1,\n",
    "    'b':1,\n",
    "    'c':1\n",
    "}\n",
    "for i, i1 in enumerate(a):\n",
    "    print(i, i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1️⃣ L2 distance (No Normalization): 7.071067810058594\n",
      "2️⃣ L2 distance (With Normalization): 0.09044332057237625\n",
      "3️⃣ L2 distance (Same vectors): 0.0\n",
      "4️⃣ L2 distance (Orthogonal vectors - No Normalization): 8.485280990600586\n",
      "5️⃣ L2 distance (Orthogonal vectors - With Normalization): 1.4142135381698608\n",
      "6️⃣ L2 distance (Opposite vectors - No Normalization): 2.8284270763397217\n",
      "7️⃣ L2 distance (Opposite vectors - With Normalization): 1.9999998807907104\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_l2_distance(emb1, emb2, normalize=False):\n",
    "    \"\"\"\n",
    "    Tính khoảng cách L2 (Euclidean distance) giữa emb1 và emb2.\n",
    "    Nếu normalize=True, vector sẽ được chuẩn hóa về norm=1 trước khi tính.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        emb1 = emb1 / torch.norm(emb1, p=2)\n",
    "        emb2 = emb2 / torch.norm(emb2, p=2)\n",
    "    \n",
    "    distance = torch.norm(emb1 - emb2, p=2).item()\n",
    "    return distance\n",
    "\n",
    "# Trường hợp 1: Hai vector bất kỳ chưa chuẩn hóa\n",
    "emb1 = torch.tensor([10.0, 20.0, 30.0])\n",
    "emb2 = torch.tensor([15.0, 24.0, 33.0])\n",
    "print(\"1️⃣ L2 distance (No Normalization):\", compute_l2_distance(emb1, emb2, normalize=False))\n",
    "print(\"2️⃣ L2 distance (With Normalization):\", compute_l2_distance(emb1, emb2, normalize=True))\n",
    "\n",
    "# Trường hợp 2: Hai vector giống nhau (khoảng cách phải = 0)\n",
    "emb1 = torch.tensor([3.0, 4.0, 5.0])\n",
    "emb2 = torch.tensor([3.0, 4.0, 5.0])\n",
    "print(\"3️⃣ L2 distance (Same vectors):\", compute_l2_distance(emb1, emb2, normalize=False))\n",
    "\n",
    "# Trường hợp 3: Hai vector vuông góc (orthogonal)\n",
    "emb1 = torch.tensor([6.0, 0.0])\n",
    "emb2 = torch.tensor([0.0, 6.0])\n",
    "print(\"4️⃣ L2 distance (Orthogonal vectors - No Normalization):\", compute_l2_distance(emb1, emb2, normalize=False))\n",
    "print(\"5️⃣ L2 distance (Orthogonal vectors - With Normalization):\", compute_l2_distance(emb1, emb2, normalize=True))\n",
    "\n",
    "# Trường hợp 4: Hai vector đối nhau (opposite direction)\n",
    "emb1 = torch.tensor([1.0, 1.0])\n",
    "emb2 = torch.tensor([-1.0, -1.0])\n",
    "print(\"6️⃣ L2 distance (Opposite vectors - No Normalization):\", compute_l2_distance(emb1, emb2, normalize=False))\n",
    "print(\"7️⃣ L2 distance (Opposite vectors - With Normalization):\", compute_l2_distance(emb1, emb2, normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--facebook--convnext-tiny-224\\snapshots\\6166b7613034066690a621d8bf25ffdf181a34f0\\preprocessor_config.json\n",
      "size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_height', 'max_width'}), got 224. Converted to {'shortest_edge': 224}.\n",
      "Image processor ConvNextImageProcessor {\n",
      "  \"crop_pct\": 0.875,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--facebook--convnext-tiny-224\\snapshots\\6166b7613034066690a621d8bf25ffdf181a34f0\\config.json\n",
      "Model config ConvNextConfig {\n",
      "  \"architectures\": [\n",
      "    \"ConvNextForImageClassification\"\n",
      "  ],\n",
      "  \"depths\": [\n",
      "    3,\n",
      "    3,\n",
      "    9,\n",
      "    3\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_sizes\": [\n",
      "    96,\n",
      "    192,\n",
      "    384,\n",
      "    768\n",
      "  ],\n",
      "  \"id2label\": {\n",
      "    \"0\": \"tench, Tinca tinca\",\n",
      "    \"1\": \"goldfish, Carassius auratus\",\n",
      "    \"2\": \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\",\n",
      "    \"3\": \"tiger shark, Galeocerdo cuvieri\",\n",
      "    \"4\": \"hammerhead, hammerhead shark\",\n",
      "    \"5\": \"electric ray, crampfish, numbfish, torpedo\",\n",
      "    \"6\": \"stingray\",\n",
      "    \"7\": \"cock\",\n",
      "    \"8\": \"hen\",\n",
      "    \"9\": \"ostrich, Struthio camelus\",\n",
      "    \"10\": \"brambling, Fringilla montifringilla\",\n",
      "    \"11\": \"goldfinch, Carduelis carduelis\",\n",
      "    \"12\": \"house finch, linnet, Carpodacus mexicanus\",\n",
      "    \"13\": \"junco, snowbird\",\n",
      "    \"14\": \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\",\n",
      "    \"15\": \"robin, American robin, Turdus migratorius\",\n",
      "    \"16\": \"bulbul\",\n",
      "    \"17\": \"jay\",\n",
      "    \"18\": \"magpie\",\n",
      "    \"19\": \"chickadee\",\n",
      "    \"20\": \"water ouzel, dipper\",\n",
      "    \"21\": \"kite\",\n",
      "    \"22\": \"bald eagle, American eagle, Haliaeetus leucocephalus\",\n",
      "    \"23\": \"vulture\",\n",
      "    \"24\": \"great grey owl, great gray owl, Strix nebulosa\",\n",
      "    \"25\": \"European fire salamander, Salamandra salamandra\",\n",
      "    \"26\": \"common newt, Triturus vulgaris\",\n",
      "    \"27\": \"eft\",\n",
      "    \"28\": \"spotted salamander, Ambystoma maculatum\",\n",
      "    \"29\": \"axolotl, mud puppy, Ambystoma mexicanum\",\n",
      "    \"30\": \"bullfrog, Rana catesbeiana\",\n",
      "    \"31\": \"tree frog, tree-frog\",\n",
      "    \"32\": \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\",\n",
      "    \"33\": \"loggerhead, loggerhead turtle, Caretta caretta\",\n",
      "    \"34\": \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\",\n",
      "    \"35\": \"mud turtle\",\n",
      "    \"36\": \"terrapin\",\n",
      "    \"37\": \"box turtle, box tortoise\",\n",
      "    \"38\": \"banded gecko\",\n",
      "    \"39\": \"common iguana, iguana, Iguana iguana\",\n",
      "    \"40\": \"American chameleon, anole, Anolis carolinensis\",\n",
      "    \"41\": \"whiptail, whiptail lizard\",\n",
      "    \"42\": \"agama\",\n",
      "    \"43\": \"frilled lizard, Chlamydosaurus kingi\",\n",
      "    \"44\": \"alligator lizard\",\n",
      "    \"45\": \"Gila monster, Heloderma suspectum\",\n",
      "    \"46\": \"green lizard, Lacerta viridis\",\n",
      "    \"47\": \"African chameleon, Chamaeleo chamaeleon\",\n",
      "    \"48\": \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\",\n",
      "    \"49\": \"African crocodile, Nile crocodile, Crocodylus niloticus\",\n",
      "    \"50\": \"American alligator, Alligator mississipiensis\",\n",
      "    \"51\": \"triceratops\",\n",
      "    \"52\": \"thunder snake, worm snake, Carphophis amoenus\",\n",
      "    \"53\": \"ringneck snake, ring-necked snake, ring snake\",\n",
      "    \"54\": \"hognose snake, puff adder, sand viper\",\n",
      "    \"55\": \"green snake, grass snake\",\n",
      "    \"56\": \"king snake, kingsnake\",\n",
      "    \"57\": \"garter snake, grass snake\",\n",
      "    \"58\": \"water snake\",\n",
      "    \"59\": \"vine snake\",\n",
      "    \"60\": \"night snake, Hypsiglena torquata\",\n",
      "    \"61\": \"boa constrictor, Constrictor constrictor\",\n",
      "    \"62\": \"rock python, rock snake, Python sebae\",\n",
      "    \"63\": \"Indian cobra, Naja naja\",\n",
      "    \"64\": \"green mamba\",\n",
      "    \"65\": \"sea snake\",\n",
      "    \"66\": \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\",\n",
      "    \"67\": \"diamondback, diamondback rattlesnake, Crotalus adamanteus\",\n",
      "    \"68\": \"sidewinder, horned rattlesnake, Crotalus cerastes\",\n",
      "    \"69\": \"trilobite\",\n",
      "    \"70\": \"harvestman, daddy longlegs, Phalangium opilio\",\n",
      "    \"71\": \"scorpion\",\n",
      "    \"72\": \"black and gold garden spider, Argiope aurantia\",\n",
      "    \"73\": \"barn spider, Araneus cavaticus\",\n",
      "    \"74\": \"garden spider, Aranea diademata\",\n",
      "    \"75\": \"black widow, Latrodectus mactans\",\n",
      "    \"76\": \"tarantula\",\n",
      "    \"77\": \"wolf spider, hunting spider\",\n",
      "    \"78\": \"tick\",\n",
      "    \"79\": \"centipede\",\n",
      "    \"80\": \"black grouse\",\n",
      "    \"81\": \"ptarmigan\",\n",
      "    \"82\": \"ruffed grouse, partridge, Bonasa umbellus\",\n",
      "    \"83\": \"prairie chicken, prairie grouse, prairie fowl\",\n",
      "    \"84\": \"peacock\",\n",
      "    \"85\": \"quail\",\n",
      "    \"86\": \"partridge\",\n",
      "    \"87\": \"African grey, African gray, Psittacus erithacus\",\n",
      "    \"88\": \"macaw\",\n",
      "    \"89\": \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\",\n",
      "    \"90\": \"lorikeet\",\n",
      "    \"91\": \"coucal\",\n",
      "    \"92\": \"bee eater\",\n",
      "    \"93\": \"hornbill\",\n",
      "    \"94\": \"hummingbird\",\n",
      "    \"95\": \"jacamar\",\n",
      "    \"96\": \"toucan\",\n",
      "    \"97\": \"drake\",\n",
      "    \"98\": \"red-breasted merganser, Mergus serrator\",\n",
      "    \"99\": \"goose\",\n",
      "    \"100\": \"black swan, Cygnus atratus\",\n",
      "    \"101\": \"tusker\",\n",
      "    \"102\": \"echidna, spiny anteater, anteater\",\n",
      "    \"103\": \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\",\n",
      "    \"104\": \"wallaby, brush kangaroo\",\n",
      "    \"105\": \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\",\n",
      "    \"106\": \"wombat\",\n",
      "    \"107\": \"jellyfish\",\n",
      "    \"108\": \"sea anemone, anemone\",\n",
      "    \"109\": \"brain coral\",\n",
      "    \"110\": \"flatworm, platyhelminth\",\n",
      "    \"111\": \"nematode, nematode worm, roundworm\",\n",
      "    \"112\": \"conch\",\n",
      "    \"113\": \"snail\",\n",
      "    \"114\": \"slug\",\n",
      "    \"115\": \"sea slug, nudibranch\",\n",
      "    \"116\": \"chiton, coat-of-mail shell, sea cradle, polyplacophore\",\n",
      "    \"117\": \"chambered nautilus, pearly nautilus, nautilus\",\n",
      "    \"118\": \"Dungeness crab, Cancer magister\",\n",
      "    \"119\": \"rock crab, Cancer irroratus\",\n",
      "    \"120\": \"fiddler crab\",\n",
      "    \"121\": \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\",\n",
      "    \"122\": \"American lobster, Northern lobster, Maine lobster, Homarus americanus\",\n",
      "    \"123\": \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\",\n",
      "    \"124\": \"crayfish, crawfish, crawdad, crawdaddy\",\n",
      "    \"125\": \"hermit crab\",\n",
      "    \"126\": \"isopod\",\n",
      "    \"127\": \"white stork, Ciconia ciconia\",\n",
      "    \"128\": \"black stork, Ciconia nigra\",\n",
      "    \"129\": \"spoonbill\",\n",
      "    \"130\": \"flamingo\",\n",
      "    \"131\": \"little blue heron, Egretta caerulea\",\n",
      "    \"132\": \"American egret, great white heron, Egretta albus\",\n",
      "    \"133\": \"bittern\",\n",
      "    \"134\": \"crane\",\n",
      "    \"135\": \"limpkin, Aramus pictus\",\n",
      "    \"136\": \"European gallinule, Porphyrio porphyrio\",\n",
      "    \"137\": \"American coot, marsh hen, mud hen, water hen, Fulica americana\",\n",
      "    \"138\": \"bustard\",\n",
      "    \"139\": \"ruddy turnstone, Arenaria interpres\",\n",
      "    \"140\": \"red-backed sandpiper, dunlin, Erolia alpina\",\n",
      "    \"141\": \"redshank, Tringa totanus\",\n",
      "    \"142\": \"dowitcher\",\n",
      "    \"143\": \"oystercatcher, oyster catcher\",\n",
      "    \"144\": \"pelican\",\n",
      "    \"145\": \"king penguin, Aptenodytes patagonica\",\n",
      "    \"146\": \"albatross, mollymawk\",\n",
      "    \"147\": \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\",\n",
      "    \"148\": \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\",\n",
      "    \"149\": \"dugong, Dugong dugon\",\n",
      "    \"150\": \"sea lion\",\n",
      "    \"151\": \"Chihuahua\",\n",
      "    \"152\": \"Japanese spaniel\",\n",
      "    \"153\": \"Maltese dog, Maltese terrier, Maltese\",\n",
      "    \"154\": \"Pekinese, Pekingese, Peke\",\n",
      "    \"155\": \"Shih-Tzu\",\n",
      "    \"156\": \"Blenheim spaniel\",\n",
      "    \"157\": \"papillon\",\n",
      "    \"158\": \"toy terrier\",\n",
      "    \"159\": \"Rhodesian ridgeback\",\n",
      "    \"160\": \"Afghan hound, Afghan\",\n",
      "    \"161\": \"basset, basset hound\",\n",
      "    \"162\": \"beagle\",\n",
      "    \"163\": \"bloodhound, sleuthhound\",\n",
      "    \"164\": \"bluetick\",\n",
      "    \"165\": \"black-and-tan coonhound\",\n",
      "    \"166\": \"Walker hound, Walker foxhound\",\n",
      "    \"167\": \"English foxhound\",\n",
      "    \"168\": \"redbone\",\n",
      "    \"169\": \"borzoi, Russian wolfhound\",\n",
      "    \"170\": \"Irish wolfhound\",\n",
      "    \"171\": \"Italian greyhound\",\n",
      "    \"172\": \"whippet\",\n",
      "    \"173\": \"Ibizan hound, Ibizan Podenco\",\n",
      "    \"174\": \"Norwegian elkhound, elkhound\",\n",
      "    \"175\": \"otterhound, otter hound\",\n",
      "    \"176\": \"Saluki, gazelle hound\",\n",
      "    \"177\": \"Scottish deerhound, deerhound\",\n",
      "    \"178\": \"Weimaraner\",\n",
      "    \"179\": \"Staffordshire bullterrier, Staffordshire bull terrier\",\n",
      "    \"180\": \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\",\n",
      "    \"181\": \"Bedlington terrier\",\n",
      "    \"182\": \"Border terrier\",\n",
      "    \"183\": \"Kerry blue terrier\",\n",
      "    \"184\": \"Irish terrier\",\n",
      "    \"185\": \"Norfolk terrier\",\n",
      "    \"186\": \"Norwich terrier\",\n",
      "    \"187\": \"Yorkshire terrier\",\n",
      "    \"188\": \"wire-haired fox terrier\",\n",
      "    \"189\": \"Lakeland terrier\",\n",
      "    \"190\": \"Sealyham terrier, Sealyham\",\n",
      "    \"191\": \"Airedale, Airedale terrier\",\n",
      "    \"192\": \"cairn, cairn terrier\",\n",
      "    \"193\": \"Australian terrier\",\n",
      "    \"194\": \"Dandie Dinmont, Dandie Dinmont terrier\",\n",
      "    \"195\": \"Boston bull, Boston terrier\",\n",
      "    \"196\": \"miniature schnauzer\",\n",
      "    \"197\": \"giant schnauzer\",\n",
      "    \"198\": \"standard schnauzer\",\n",
      "    \"199\": \"Scotch terrier, Scottish terrier, Scottie\",\n",
      "    \"200\": \"Tibetan terrier, chrysanthemum dog\",\n",
      "    \"201\": \"silky terrier, Sydney silky\",\n",
      "    \"202\": \"soft-coated wheaten terrier\",\n",
      "    \"203\": \"West Highland white terrier\",\n",
      "    \"204\": \"Lhasa, Lhasa apso\",\n",
      "    \"205\": \"flat-coated retriever\",\n",
      "    \"206\": \"curly-coated retriever\",\n",
      "    \"207\": \"golden retriever\",\n",
      "    \"208\": \"Labrador retriever\",\n",
      "    \"209\": \"Chesapeake Bay retriever\",\n",
      "    \"210\": \"German short-haired pointer\",\n",
      "    \"211\": \"vizsla, Hungarian pointer\",\n",
      "    \"212\": \"English setter\",\n",
      "    \"213\": \"Irish setter, red setter\",\n",
      "    \"214\": \"Gordon setter\",\n",
      "    \"215\": \"Brittany spaniel\",\n",
      "    \"216\": \"clumber, clumber spaniel\",\n",
      "    \"217\": \"English springer, English springer spaniel\",\n",
      "    \"218\": \"Welsh springer spaniel\",\n",
      "    \"219\": \"cocker spaniel, English cocker spaniel, cocker\",\n",
      "    \"220\": \"Sussex spaniel\",\n",
      "    \"221\": \"Irish water spaniel\",\n",
      "    \"222\": \"kuvasz\",\n",
      "    \"223\": \"schipperke\",\n",
      "    \"224\": \"groenendael\",\n",
      "    \"225\": \"malinois\",\n",
      "    \"226\": \"briard\",\n",
      "    \"227\": \"kelpie\",\n",
      "    \"228\": \"komondor\",\n",
      "    \"229\": \"Old English sheepdog, bobtail\",\n",
      "    \"230\": \"Shetland sheepdog, Shetland sheep dog, Shetland\",\n",
      "    \"231\": \"collie\",\n",
      "    \"232\": \"Border collie\",\n",
      "    \"233\": \"Bouvier des Flandres, Bouviers des Flandres\",\n",
      "    \"234\": \"Rottweiler\",\n",
      "    \"235\": \"German shepherd, German shepherd dog, German police dog, alsatian\",\n",
      "    \"236\": \"Doberman, Doberman pinscher\",\n",
      "    \"237\": \"miniature pinscher\",\n",
      "    \"238\": \"Greater Swiss Mountain dog\",\n",
      "    \"239\": \"Bernese mountain dog\",\n",
      "    \"240\": \"Appenzeller\",\n",
      "    \"241\": \"EntleBucher\",\n",
      "    \"242\": \"boxer\",\n",
      "    \"243\": \"bull mastiff\",\n",
      "    \"244\": \"Tibetan mastiff\",\n",
      "    \"245\": \"French bulldog\",\n",
      "    \"246\": \"Great Dane\",\n",
      "    \"247\": \"Saint Bernard, St Bernard\",\n",
      "    \"248\": \"Eskimo dog, husky\",\n",
      "    \"249\": \"malamute, malemute, Alaskan malamute\",\n",
      "    \"250\": \"Siberian husky\",\n",
      "    \"251\": \"dalmatian, coach dog, carriage dog\",\n",
      "    \"252\": \"affenpinscher, monkey pinscher, monkey dog\",\n",
      "    \"253\": \"basenji\",\n",
      "    \"254\": \"pug, pug-dog\",\n",
      "    \"255\": \"Leonberg\",\n",
      "    \"256\": \"Newfoundland, Newfoundland dog\",\n",
      "    \"257\": \"Great Pyrenees\",\n",
      "    \"258\": \"Samoyed, Samoyede\",\n",
      "    \"259\": \"Pomeranian\",\n",
      "    \"260\": \"chow, chow chow\",\n",
      "    \"261\": \"keeshond\",\n",
      "    \"262\": \"Brabancon griffon\",\n",
      "    \"263\": \"Pembroke, Pembroke Welsh corgi\",\n",
      "    \"264\": \"Cardigan, Cardigan Welsh corgi\",\n",
      "    \"265\": \"toy poodle\",\n",
      "    \"266\": \"miniature poodle\",\n",
      "    \"267\": \"standard poodle\",\n",
      "    \"268\": \"Mexican hairless\",\n",
      "    \"269\": \"timber wolf, grey wolf, gray wolf, Canis lupus\",\n",
      "    \"270\": \"white wolf, Arctic wolf, Canis lupus tundrarum\",\n",
      "    \"271\": \"red wolf, maned wolf, Canis rufus, Canis niger\",\n",
      "    \"272\": \"coyote, prairie wolf, brush wolf, Canis latrans\",\n",
      "    \"273\": \"dingo, warrigal, warragal, Canis dingo\",\n",
      "    \"274\": \"dhole, Cuon alpinus\",\n",
      "    \"275\": \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\",\n",
      "    \"276\": \"hyena, hyaena\",\n",
      "    \"277\": \"red fox, Vulpes vulpes\",\n",
      "    \"278\": \"kit fox, Vulpes macrotis\",\n",
      "    \"279\": \"Arctic fox, white fox, Alopex lagopus\",\n",
      "    \"280\": \"grey fox, gray fox, Urocyon cinereoargenteus\",\n",
      "    \"281\": \"tabby, tabby cat\",\n",
      "    \"282\": \"tiger cat\",\n",
      "    \"283\": \"Persian cat\",\n",
      "    \"284\": \"Siamese cat, Siamese\",\n",
      "    \"285\": \"Egyptian cat\",\n",
      "    \"286\": \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\",\n",
      "    \"287\": \"lynx, catamount\",\n",
      "    \"288\": \"leopard, Panthera pardus\",\n",
      "    \"289\": \"snow leopard, ounce, Panthera uncia\",\n",
      "    \"290\": \"jaguar, panther, Panthera onca, Felis onca\",\n",
      "    \"291\": \"lion, king of beasts, Panthera leo\",\n",
      "    \"292\": \"tiger, Panthera tigris\",\n",
      "    \"293\": \"cheetah, chetah, Acinonyx jubatus\",\n",
      "    \"294\": \"brown bear, bruin, Ursus arctos\",\n",
      "    \"295\": \"American black bear, black bear, Ursus americanus, Euarctos americanus\",\n",
      "    \"296\": \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\",\n",
      "    \"297\": \"sloth bear, Melursus ursinus, Ursus ursinus\",\n",
      "    \"298\": \"mongoose\",\n",
      "    \"299\": \"meerkat, mierkat\",\n",
      "    \"300\": \"tiger beetle\",\n",
      "    \"301\": \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\",\n",
      "    \"302\": \"ground beetle, carabid beetle\",\n",
      "    \"303\": \"long-horned beetle, longicorn, longicorn beetle\",\n",
      "    \"304\": \"leaf beetle, chrysomelid\",\n",
      "    \"305\": \"dung beetle\",\n",
      "    \"306\": \"rhinoceros beetle\",\n",
      "    \"307\": \"weevil\",\n",
      "    \"308\": \"fly\",\n",
      "    \"309\": \"bee\",\n",
      "    \"310\": \"ant, emmet, pismire\",\n",
      "    \"311\": \"grasshopper, hopper\",\n",
      "    \"312\": \"cricket\",\n",
      "    \"313\": \"walking stick, walkingstick, stick insect\",\n",
      "    \"314\": \"cockroach, roach\",\n",
      "    \"315\": \"mantis, mantid\",\n",
      "    \"316\": \"cicada, cicala\",\n",
      "    \"317\": \"leafhopper\",\n",
      "    \"318\": \"lacewing, lacewing fly\",\n",
      "    \"319\": \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\",\n",
      "    \"320\": \"damselfly\",\n",
      "    \"321\": \"admiral\",\n",
      "    \"322\": \"ringlet, ringlet butterfly\",\n",
      "    \"323\": \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\",\n",
      "    \"324\": \"cabbage butterfly\",\n",
      "    \"325\": \"sulphur butterfly, sulfur butterfly\",\n",
      "    \"326\": \"lycaenid, lycaenid butterfly\",\n",
      "    \"327\": \"starfish, sea star\",\n",
      "    \"328\": \"sea urchin\",\n",
      "    \"329\": \"sea cucumber, holothurian\",\n",
      "    \"330\": \"wood rabbit, cottontail, cottontail rabbit\",\n",
      "    \"331\": \"hare\",\n",
      "    \"332\": \"Angora, Angora rabbit\",\n",
      "    \"333\": \"hamster\",\n",
      "    \"334\": \"porcupine, hedgehog\",\n",
      "    \"335\": \"fox squirrel, eastern fox squirrel, Sciurus niger\",\n",
      "    \"336\": \"marmot\",\n",
      "    \"337\": \"beaver\",\n",
      "    \"338\": \"guinea pig, Cavia cobaya\",\n",
      "    \"339\": \"sorrel\",\n",
      "    \"340\": \"zebra\",\n",
      "    \"341\": \"hog, pig, grunter, squealer, Sus scrofa\",\n",
      "    \"342\": \"wild boar, boar, Sus scrofa\",\n",
      "    \"343\": \"warthog\",\n",
      "    \"344\": \"hippopotamus, hippo, river horse, Hippopotamus amphibius\",\n",
      "    \"345\": \"ox\",\n",
      "    \"346\": \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\",\n",
      "    \"347\": \"bison\",\n",
      "    \"348\": \"ram, tup\",\n",
      "    \"349\": \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\",\n",
      "    \"350\": \"ibex, Capra ibex\",\n",
      "    \"351\": \"hartebeest\",\n",
      "    \"352\": \"impala, Aepyceros melampus\",\n",
      "    \"353\": \"gazelle\",\n",
      "    \"354\": \"Arabian camel, dromedary, Camelus dromedarius\",\n",
      "    \"355\": \"llama\",\n",
      "    \"356\": \"weasel\",\n",
      "    \"357\": \"mink\",\n",
      "    \"358\": \"polecat, fitch, foulmart, foumart, Mustela putorius\",\n",
      "    \"359\": \"black-footed ferret, ferret, Mustela nigripes\",\n",
      "    \"360\": \"otter\",\n",
      "    \"361\": \"skunk, polecat, wood pussy\",\n",
      "    \"362\": \"badger\",\n",
      "    \"363\": \"armadillo\",\n",
      "    \"364\": \"three-toed sloth, ai, Bradypus tridactylus\",\n",
      "    \"365\": \"orangutan, orang, orangutang, Pongo pygmaeus\",\n",
      "    \"366\": \"gorilla, Gorilla gorilla\",\n",
      "    \"367\": \"chimpanzee, chimp, Pan troglodytes\",\n",
      "    \"368\": \"gibbon, Hylobates lar\",\n",
      "    \"369\": \"siamang, Hylobates syndactylus, Symphalangus syndactylus\",\n",
      "    \"370\": \"guenon, guenon monkey\",\n",
      "    \"371\": \"patas, hussar monkey, Erythrocebus patas\",\n",
      "    \"372\": \"baboon\",\n",
      "    \"373\": \"macaque\",\n",
      "    \"374\": \"langur\",\n",
      "    \"375\": \"colobus, colobus monkey\",\n",
      "    \"376\": \"proboscis monkey, Nasalis larvatus\",\n",
      "    \"377\": \"marmoset\",\n",
      "    \"378\": \"capuchin, ringtail, Cebus capucinus\",\n",
      "    \"379\": \"howler monkey, howler\",\n",
      "    \"380\": \"titi, titi monkey\",\n",
      "    \"381\": \"spider monkey, Ateles geoffroyi\",\n",
      "    \"382\": \"squirrel monkey, Saimiri sciureus\",\n",
      "    \"383\": \"Madagascar cat, ring-tailed lemur, Lemur catta\",\n",
      "    \"384\": \"indri, indris, Indri indri, Indri brevicaudatus\",\n",
      "    \"385\": \"Indian elephant, Elephas maximus\",\n",
      "    \"386\": \"African elephant, Loxodonta africana\",\n",
      "    \"387\": \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\",\n",
      "    \"388\": \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\",\n",
      "    \"389\": \"barracouta, snoek\",\n",
      "    \"390\": \"eel\",\n",
      "    \"391\": \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\",\n",
      "    \"392\": \"rock beauty, Holocanthus tricolor\",\n",
      "    \"393\": \"anemone fish\",\n",
      "    \"394\": \"sturgeon\",\n",
      "    \"395\": \"gar, garfish, garpike, billfish, Lepisosteus osseus\",\n",
      "    \"396\": \"lionfish\",\n",
      "    \"397\": \"puffer, pufferfish, blowfish, globefish\",\n",
      "    \"398\": \"abacus\",\n",
      "    \"399\": \"abaya\",\n",
      "    \"400\": \"academic gown, academic robe, judge's robe\",\n",
      "    \"401\": \"accordion, piano accordion, squeeze box\",\n",
      "    \"402\": \"acoustic guitar\",\n",
      "    \"403\": \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n",
      "    \"404\": \"airliner\",\n",
      "    \"405\": \"airship, dirigible\",\n",
      "    \"406\": \"altar\",\n",
      "    \"407\": \"ambulance\",\n",
      "    \"408\": \"amphibian, amphibious vehicle\",\n",
      "    \"409\": \"analog clock\",\n",
      "    \"410\": \"apiary, bee house\",\n",
      "    \"411\": \"apron\",\n",
      "    \"412\": \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\",\n",
      "    \"413\": \"assault rifle, assault gun\",\n",
      "    \"414\": \"backpack, back pack, knapsack, packsack, rucksack, haversack\",\n",
      "    \"415\": \"bakery, bakeshop, bakehouse\",\n",
      "    \"416\": \"balance beam, beam\",\n",
      "    \"417\": \"balloon\",\n",
      "    \"418\": \"ballpoint, ballpoint pen, ballpen, Biro\",\n",
      "    \"419\": \"Band Aid\",\n",
      "    \"420\": \"banjo\",\n",
      "    \"421\": \"bannister, banister, balustrade, balusters, handrail\",\n",
      "    \"422\": \"barbell\",\n",
      "    \"423\": \"barber chair\",\n",
      "    \"424\": \"barbershop\",\n",
      "    \"425\": \"barn\",\n",
      "    \"426\": \"barometer\",\n",
      "    \"427\": \"barrel, cask\",\n",
      "    \"428\": \"barrow, garden cart, lawn cart, wheelbarrow\",\n",
      "    \"429\": \"baseball\",\n",
      "    \"430\": \"basketball\",\n",
      "    \"431\": \"bassinet\",\n",
      "    \"432\": \"bassoon\",\n",
      "    \"433\": \"bathing cap, swimming cap\",\n",
      "    \"434\": \"bath towel\",\n",
      "    \"435\": \"bathtub, bathing tub, bath, tub\",\n",
      "    \"436\": \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\",\n",
      "    \"437\": \"beacon, lighthouse, beacon light, pharos\",\n",
      "    \"438\": \"beaker\",\n",
      "    \"439\": \"bearskin, busby, shako\",\n",
      "    \"440\": \"beer bottle\",\n",
      "    \"441\": \"beer glass\",\n",
      "    \"442\": \"bell cote, bell cot\",\n",
      "    \"443\": \"bib\",\n",
      "    \"444\": \"bicycle-built-for-two, tandem bicycle, tandem\",\n",
      "    \"445\": \"bikini, two-piece\",\n",
      "    \"446\": \"binder, ring-binder\",\n",
      "    \"447\": \"binoculars, field glasses, opera glasses\",\n",
      "    \"448\": \"birdhouse\",\n",
      "    \"449\": \"boathouse\",\n",
      "    \"450\": \"bobsled, bobsleigh, bob\",\n",
      "    \"451\": \"bolo tie, bolo, bola tie, bola\",\n",
      "    \"452\": \"bonnet, poke bonnet\",\n",
      "    \"453\": \"bookcase\",\n",
      "    \"454\": \"bookshop, bookstore, bookstall\",\n",
      "    \"455\": \"bottlecap\",\n",
      "    \"456\": \"bow\",\n",
      "    \"457\": \"bow tie, bow-tie, bowtie\",\n",
      "    \"458\": \"brass, memorial tablet, plaque\",\n",
      "    \"459\": \"brassiere, bra, bandeau\",\n",
      "    \"460\": \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\",\n",
      "    \"461\": \"breastplate, aegis, egis\",\n",
      "    \"462\": \"broom\",\n",
      "    \"463\": \"bucket, pail\",\n",
      "    \"464\": \"buckle\",\n",
      "    \"465\": \"bulletproof vest\",\n",
      "    \"466\": \"bullet train, bullet\",\n",
      "    \"467\": \"butcher shop, meat market\",\n",
      "    \"468\": \"cab, hack, taxi, taxicab\",\n",
      "    \"469\": \"caldron, cauldron\",\n",
      "    \"470\": \"candle, taper, wax light\",\n",
      "    \"471\": \"cannon\",\n",
      "    \"472\": \"canoe\",\n",
      "    \"473\": \"can opener, tin opener\",\n",
      "    \"474\": \"cardigan\",\n",
      "    \"475\": \"car mirror\",\n",
      "    \"476\": \"carousel, carrousel, merry-go-round, roundabout, whirligig\",\n",
      "    \"477\": \"carpenter's kit, tool kit\",\n",
      "    \"478\": \"carton\",\n",
      "    \"479\": \"car wheel\",\n",
      "    \"480\": \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\",\n",
      "    \"481\": \"cassette\",\n",
      "    \"482\": \"cassette player\",\n",
      "    \"483\": \"castle\",\n",
      "    \"484\": \"catamaran\",\n",
      "    \"485\": \"CD player\",\n",
      "    \"486\": \"cello, violoncello\",\n",
      "    \"487\": \"cellular telephone, cellular phone, cellphone, cell, mobile phone\",\n",
      "    \"488\": \"chain\",\n",
      "    \"489\": \"chainlink fence\",\n",
      "    \"490\": \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\",\n",
      "    \"491\": \"chain saw, chainsaw\",\n",
      "    \"492\": \"chest\",\n",
      "    \"493\": \"chiffonier, commode\",\n",
      "    \"494\": \"chime, bell, gong\",\n",
      "    \"495\": \"china cabinet, china closet\",\n",
      "    \"496\": \"Christmas stocking\",\n",
      "    \"497\": \"church, church building\",\n",
      "    \"498\": \"cinema, movie theater, movie theatre, movie house, picture palace\",\n",
      "    \"499\": \"cleaver, meat cleaver, chopper\",\n",
      "    \"500\": \"cliff dwelling\",\n",
      "    \"501\": \"cloak\",\n",
      "    \"502\": \"clog, geta, patten, sabot\",\n",
      "    \"503\": \"cocktail shaker\",\n",
      "    \"504\": \"coffee mug\",\n",
      "    \"505\": \"coffeepot\",\n",
      "    \"506\": \"coil, spiral, volute, whorl, helix\",\n",
      "    \"507\": \"combination lock\",\n",
      "    \"508\": \"computer keyboard, keypad\",\n",
      "    \"509\": \"confectionery, confectionary, candy store\",\n",
      "    \"510\": \"container ship, containership, container vessel\",\n",
      "    \"511\": \"convertible\",\n",
      "    \"512\": \"corkscrew, bottle screw\",\n",
      "    \"513\": \"cornet, horn, trumpet, trump\",\n",
      "    \"514\": \"cowboy boot\",\n",
      "    \"515\": \"cowboy hat, ten-gallon hat\",\n",
      "    \"516\": \"cradle\",\n",
      "    \"517\": \"crane\",\n",
      "    \"518\": \"crash helmet\",\n",
      "    \"519\": \"crate\",\n",
      "    \"520\": \"crib, cot\",\n",
      "    \"521\": \"Crock Pot\",\n",
      "    \"522\": \"croquet ball\",\n",
      "    \"523\": \"crutch\",\n",
      "    \"524\": \"cuirass\",\n",
      "    \"525\": \"dam, dike, dyke\",\n",
      "    \"526\": \"desk\",\n",
      "    \"527\": \"desktop computer\",\n",
      "    \"528\": \"dial telephone, dial phone\",\n",
      "    \"529\": \"diaper, nappy, napkin\",\n",
      "    \"530\": \"digital clock\",\n",
      "    \"531\": \"digital watch\",\n",
      "    \"532\": \"dining table, board\",\n",
      "    \"533\": \"dishrag, dishcloth\",\n",
      "    \"534\": \"dishwasher, dish washer, dishwashing machine\",\n",
      "    \"535\": \"disk brake, disc brake\",\n",
      "    \"536\": \"dock, dockage, docking facility\",\n",
      "    \"537\": \"dogsled, dog sled, dog sleigh\",\n",
      "    \"538\": \"dome\",\n",
      "    \"539\": \"doormat, welcome mat\",\n",
      "    \"540\": \"drilling platform, offshore rig\",\n",
      "    \"541\": \"drum, membranophone, tympan\",\n",
      "    \"542\": \"drumstick\",\n",
      "    \"543\": \"dumbbell\",\n",
      "    \"544\": \"Dutch oven\",\n",
      "    \"545\": \"electric fan, blower\",\n",
      "    \"546\": \"electric guitar\",\n",
      "    \"547\": \"electric locomotive\",\n",
      "    \"548\": \"entertainment center\",\n",
      "    \"549\": \"envelope\",\n",
      "    \"550\": \"espresso maker\",\n",
      "    \"551\": \"face powder\",\n",
      "    \"552\": \"feather boa, boa\",\n",
      "    \"553\": \"file, file cabinet, filing cabinet\",\n",
      "    \"554\": \"fireboat\",\n",
      "    \"555\": \"fire engine, fire truck\",\n",
      "    \"556\": \"fire screen, fireguard\",\n",
      "    \"557\": \"flagpole, flagstaff\",\n",
      "    \"558\": \"flute, transverse flute\",\n",
      "    \"559\": \"folding chair\",\n",
      "    \"560\": \"football helmet\",\n",
      "    \"561\": \"forklift\",\n",
      "    \"562\": \"fountain\",\n",
      "    \"563\": \"fountain pen\",\n",
      "    \"564\": \"four-poster\",\n",
      "    \"565\": \"freight car\",\n",
      "    \"566\": \"French horn, horn\",\n",
      "    \"567\": \"frying pan, frypan, skillet\",\n",
      "    \"568\": \"fur coat\",\n",
      "    \"569\": \"garbage truck, dustcart\",\n",
      "    \"570\": \"gasmask, respirator, gas helmet\",\n",
      "    \"571\": \"gas pump, gasoline pump, petrol pump, island dispenser\",\n",
      "    \"572\": \"goblet\",\n",
      "    \"573\": \"go-kart\",\n",
      "    \"574\": \"golf ball\",\n",
      "    \"575\": \"golfcart, golf cart\",\n",
      "    \"576\": \"gondola\",\n",
      "    \"577\": \"gong, tam-tam\",\n",
      "    \"578\": \"gown\",\n",
      "    \"579\": \"grand piano, grand\",\n",
      "    \"580\": \"greenhouse, nursery, glasshouse\",\n",
      "    \"581\": \"grille, radiator grille\",\n",
      "    \"582\": \"grocery store, grocery, food market, market\",\n",
      "    \"583\": \"guillotine\",\n",
      "    \"584\": \"hair slide\",\n",
      "    \"585\": \"hair spray\",\n",
      "    \"586\": \"half track\",\n",
      "    \"587\": \"hammer\",\n",
      "    \"588\": \"hamper\",\n",
      "    \"589\": \"hand blower, blow dryer, blow drier, hair dryer, hair drier\",\n",
      "    \"590\": \"hand-held computer, hand-held microcomputer\",\n",
      "    \"591\": \"handkerchief, hankie, hanky, hankey\",\n",
      "    \"592\": \"hard disc, hard disk, fixed disk\",\n",
      "    \"593\": \"harmonica, mouth organ, harp, mouth harp\",\n",
      "    \"594\": \"harp\",\n",
      "    \"595\": \"harvester, reaper\",\n",
      "    \"596\": \"hatchet\",\n",
      "    \"597\": \"holster\",\n",
      "    \"598\": \"home theater, home theatre\",\n",
      "    \"599\": \"honeycomb\",\n",
      "    \"600\": \"hook, claw\",\n",
      "    \"601\": \"hoopskirt, crinoline\",\n",
      "    \"602\": \"horizontal bar, high bar\",\n",
      "    \"603\": \"horse cart, horse-cart\",\n",
      "    \"604\": \"hourglass\",\n",
      "    \"605\": \"iPod\",\n",
      "    \"606\": \"iron, smoothing iron\",\n",
      "    \"607\": \"jack-o'-lantern\",\n",
      "    \"608\": \"jean, blue jean, denim\",\n",
      "    \"609\": \"jeep, landrover\",\n",
      "    \"610\": \"jersey, T-shirt, tee shirt\",\n",
      "    \"611\": \"jigsaw puzzle\",\n",
      "    \"612\": \"jinrikisha, ricksha, rickshaw\",\n",
      "    \"613\": \"joystick\",\n",
      "    \"614\": \"kimono\",\n",
      "    \"615\": \"knee pad\",\n",
      "    \"616\": \"knot\",\n",
      "    \"617\": \"lab coat, laboratory coat\",\n",
      "    \"618\": \"ladle\",\n",
      "    \"619\": \"lampshade, lamp shade\",\n",
      "    \"620\": \"laptop, laptop computer\",\n",
      "    \"621\": \"lawn mower, mower\",\n",
      "    \"622\": \"lens cap, lens cover\",\n",
      "    \"623\": \"letter opener, paper knife, paperknife\",\n",
      "    \"624\": \"library\",\n",
      "    \"625\": \"lifeboat\",\n",
      "    \"626\": \"lighter, light, igniter, ignitor\",\n",
      "    \"627\": \"limousine, limo\",\n",
      "    \"628\": \"liner, ocean liner\",\n",
      "    \"629\": \"lipstick, lip rouge\",\n",
      "    \"630\": \"Loafer\",\n",
      "    \"631\": \"lotion\",\n",
      "    \"632\": \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\",\n",
      "    \"633\": \"loupe, jeweler's loupe\",\n",
      "    \"634\": \"lumbermill, sawmill\",\n",
      "    \"635\": \"magnetic compass\",\n",
      "    \"636\": \"mailbag, postbag\",\n",
      "    \"637\": \"mailbox, letter box\",\n",
      "    \"638\": \"maillot\",\n",
      "    \"639\": \"maillot, tank suit\",\n",
      "    \"640\": \"manhole cover\",\n",
      "    \"641\": \"maraca\",\n",
      "    \"642\": \"marimba, xylophone\",\n",
      "    \"643\": \"mask\",\n",
      "    \"644\": \"matchstick\",\n",
      "    \"645\": \"maypole\",\n",
      "    \"646\": \"maze, labyrinth\",\n",
      "    \"647\": \"measuring cup\",\n",
      "    \"648\": \"medicine chest, medicine cabinet\",\n",
      "    \"649\": \"megalith, megalithic structure\",\n",
      "    \"650\": \"microphone, mike\",\n",
      "    \"651\": \"microwave, microwave oven\",\n",
      "    \"652\": \"military uniform\",\n",
      "    \"653\": \"milk can\",\n",
      "    \"654\": \"minibus\",\n",
      "    \"655\": \"miniskirt, mini\",\n",
      "    \"656\": \"minivan\",\n",
      "    \"657\": \"missile\",\n",
      "    \"658\": \"mitten\",\n",
      "    \"659\": \"mixing bowl\",\n",
      "    \"660\": \"mobile home, manufactured home\",\n",
      "    \"661\": \"Model T\",\n",
      "    \"662\": \"modem\",\n",
      "    \"663\": \"monastery\",\n",
      "    \"664\": \"monitor\",\n",
      "    \"665\": \"moped\",\n",
      "    \"666\": \"mortar\",\n",
      "    \"667\": \"mortarboard\",\n",
      "    \"668\": \"mosque\",\n",
      "    \"669\": \"mosquito net\",\n",
      "    \"670\": \"motor scooter, scooter\",\n",
      "    \"671\": \"mountain bike, all-terrain bike, off-roader\",\n",
      "    \"672\": \"mountain tent\",\n",
      "    \"673\": \"mouse, computer mouse\",\n",
      "    \"674\": \"mousetrap\",\n",
      "    \"675\": \"moving van\",\n",
      "    \"676\": \"muzzle\",\n",
      "    \"677\": \"nail\",\n",
      "    \"678\": \"neck brace\",\n",
      "    \"679\": \"necklace\",\n",
      "    \"680\": \"nipple\",\n",
      "    \"681\": \"notebook, notebook computer\",\n",
      "    \"682\": \"obelisk\",\n",
      "    \"683\": \"oboe, hautboy, hautbois\",\n",
      "    \"684\": \"ocarina, sweet potato\",\n",
      "    \"685\": \"odometer, hodometer, mileometer, milometer\",\n",
      "    \"686\": \"oil filter\",\n",
      "    \"687\": \"organ, pipe organ\",\n",
      "    \"688\": \"oscilloscope, scope, cathode-ray oscilloscope, CRO\",\n",
      "    \"689\": \"overskirt\",\n",
      "    \"690\": \"oxcart\",\n",
      "    \"691\": \"oxygen mask\",\n",
      "    \"692\": \"packet\",\n",
      "    \"693\": \"paddle, boat paddle\",\n",
      "    \"694\": \"paddlewheel, paddle wheel\",\n",
      "    \"695\": \"padlock\",\n",
      "    \"696\": \"paintbrush\",\n",
      "    \"697\": \"pajama, pyjama, pj's, jammies\",\n",
      "    \"698\": \"palace\",\n",
      "    \"699\": \"panpipe, pandean pipe, syrinx\",\n",
      "    \"700\": \"paper towel\",\n",
      "    \"701\": \"parachute, chute\",\n",
      "    \"702\": \"parallel bars, bars\",\n",
      "    \"703\": \"park bench\",\n",
      "    \"704\": \"parking meter\",\n",
      "    \"705\": \"passenger car, coach, carriage\",\n",
      "    \"706\": \"patio, terrace\",\n",
      "    \"707\": \"pay-phone, pay-station\",\n",
      "    \"708\": \"pedestal, plinth, footstall\",\n",
      "    \"709\": \"pencil box, pencil case\",\n",
      "    \"710\": \"pencil sharpener\",\n",
      "    \"711\": \"perfume, essence\",\n",
      "    \"712\": \"Petri dish\",\n",
      "    \"713\": \"photocopier\",\n",
      "    \"714\": \"pick, plectrum, plectron\",\n",
      "    \"715\": \"pickelhaube\",\n",
      "    \"716\": \"picket fence, paling\",\n",
      "    \"717\": \"pickup, pickup truck\",\n",
      "    \"718\": \"pier\",\n",
      "    \"719\": \"piggy bank, penny bank\",\n",
      "    \"720\": \"pill bottle\",\n",
      "    \"721\": \"pillow\",\n",
      "    \"722\": \"ping-pong ball\",\n",
      "    \"723\": \"pinwheel\",\n",
      "    \"724\": \"pirate, pirate ship\",\n",
      "    \"725\": \"pitcher, ewer\",\n",
      "    \"726\": \"plane, carpenter's plane, woodworking plane\",\n",
      "    \"727\": \"planetarium\",\n",
      "    \"728\": \"plastic bag\",\n",
      "    \"729\": \"plate rack\",\n",
      "    \"730\": \"plow, plough\",\n",
      "    \"731\": \"plunger, plumber's helper\",\n",
      "    \"732\": \"Polaroid camera, Polaroid Land camera\",\n",
      "    \"733\": \"pole\",\n",
      "    \"734\": \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\",\n",
      "    \"735\": \"poncho\",\n",
      "    \"736\": \"pool table, billiard table, snooker table\",\n",
      "    \"737\": \"pop bottle, soda bottle\",\n",
      "    \"738\": \"pot, flowerpot\",\n",
      "    \"739\": \"potter's wheel\",\n",
      "    \"740\": \"power drill\",\n",
      "    \"741\": \"prayer rug, prayer mat\",\n",
      "    \"742\": \"printer\",\n",
      "    \"743\": \"prison, prison house\",\n",
      "    \"744\": \"projectile, missile\",\n",
      "    \"745\": \"projector\",\n",
      "    \"746\": \"puck, hockey puck\",\n",
      "    \"747\": \"punching bag, punch bag, punching ball, punchball\",\n",
      "    \"748\": \"purse\",\n",
      "    \"749\": \"quill, quill pen\",\n",
      "    \"750\": \"quilt, comforter, comfort, puff\",\n",
      "    \"751\": \"racer, race car, racing car\",\n",
      "    \"752\": \"racket, racquet\",\n",
      "    \"753\": \"radiator\",\n",
      "    \"754\": \"radio, wireless\",\n",
      "    \"755\": \"radio telescope, radio reflector\",\n",
      "    \"756\": \"rain barrel\",\n",
      "    \"757\": \"recreational vehicle, RV, R.V.\",\n",
      "    \"758\": \"reel\",\n",
      "    \"759\": \"reflex camera\",\n",
      "    \"760\": \"refrigerator, icebox\",\n",
      "    \"761\": \"remote control, remote\",\n",
      "    \"762\": \"restaurant, eating house, eating place, eatery\",\n",
      "    \"763\": \"revolver, six-gun, six-shooter\",\n",
      "    \"764\": \"rifle\",\n",
      "    \"765\": \"rocking chair, rocker\",\n",
      "    \"766\": \"rotisserie\",\n",
      "    \"767\": \"rubber eraser, rubber, pencil eraser\",\n",
      "    \"768\": \"rugby ball\",\n",
      "    \"769\": \"rule, ruler\",\n",
      "    \"770\": \"running shoe\",\n",
      "    \"771\": \"safe\",\n",
      "    \"772\": \"safety pin\",\n",
      "    \"773\": \"saltshaker, salt shaker\",\n",
      "    \"774\": \"sandal\",\n",
      "    \"775\": \"sarong\",\n",
      "    \"776\": \"sax, saxophone\",\n",
      "    \"777\": \"scabbard\",\n",
      "    \"778\": \"scale, weighing machine\",\n",
      "    \"779\": \"school bus\",\n",
      "    \"780\": \"schooner\",\n",
      "    \"781\": \"scoreboard\",\n",
      "    \"782\": \"screen, CRT screen\",\n",
      "    \"783\": \"screw\",\n",
      "    \"784\": \"screwdriver\",\n",
      "    \"785\": \"seat belt, seatbelt\",\n",
      "    \"786\": \"sewing machine\",\n",
      "    \"787\": \"shield, buckler\",\n",
      "    \"788\": \"shoe shop, shoe-shop, shoe store\",\n",
      "    \"789\": \"shoji\",\n",
      "    \"790\": \"shopping basket\",\n",
      "    \"791\": \"shopping cart\",\n",
      "    \"792\": \"shovel\",\n",
      "    \"793\": \"shower cap\",\n",
      "    \"794\": \"shower curtain\",\n",
      "    \"795\": \"ski\",\n",
      "    \"796\": \"ski mask\",\n",
      "    \"797\": \"sleeping bag\",\n",
      "    \"798\": \"slide rule, slipstick\",\n",
      "    \"799\": \"sliding door\",\n",
      "    \"800\": \"slot, one-armed bandit\",\n",
      "    \"801\": \"snorkel\",\n",
      "    \"802\": \"snowmobile\",\n",
      "    \"803\": \"snowplow, snowplough\",\n",
      "    \"804\": \"soap dispenser\",\n",
      "    \"805\": \"soccer ball\",\n",
      "    \"806\": \"sock\",\n",
      "    \"807\": \"solar dish, solar collector, solar furnace\",\n",
      "    \"808\": \"sombrero\",\n",
      "    \"809\": \"soup bowl\",\n",
      "    \"810\": \"space bar\",\n",
      "    \"811\": \"space heater\",\n",
      "    \"812\": \"space shuttle\",\n",
      "    \"813\": \"spatula\",\n",
      "    \"814\": \"speedboat\",\n",
      "    \"815\": \"spider web, spider's web\",\n",
      "    \"816\": \"spindle\",\n",
      "    \"817\": \"sports car, sport car\",\n",
      "    \"818\": \"spotlight, spot\",\n",
      "    \"819\": \"stage\",\n",
      "    \"820\": \"steam locomotive\",\n",
      "    \"821\": \"steel arch bridge\",\n",
      "    \"822\": \"steel drum\",\n",
      "    \"823\": \"stethoscope\",\n",
      "    \"824\": \"stole\",\n",
      "    \"825\": \"stone wall\",\n",
      "    \"826\": \"stopwatch, stop watch\",\n",
      "    \"827\": \"stove\",\n",
      "    \"828\": \"strainer\",\n",
      "    \"829\": \"streetcar, tram, tramcar, trolley, trolley car\",\n",
      "    \"830\": \"stretcher\",\n",
      "    \"831\": \"studio couch, day bed\",\n",
      "    \"832\": \"stupa, tope\",\n",
      "    \"833\": \"submarine, pigboat, sub, U-boat\",\n",
      "    \"834\": \"suit, suit of clothes\",\n",
      "    \"835\": \"sundial\",\n",
      "    \"836\": \"sunglass\",\n",
      "    \"837\": \"sunglasses, dark glasses, shades\",\n",
      "    \"838\": \"sunscreen, sunblock, sun blocker\",\n",
      "    \"839\": \"suspension bridge\",\n",
      "    \"840\": \"swab, swob, mop\",\n",
      "    \"841\": \"sweatshirt\",\n",
      "    \"842\": \"swimming trunks, bathing trunks\",\n",
      "    \"843\": \"swing\",\n",
      "    \"844\": \"switch, electric switch, electrical switch\",\n",
      "    \"845\": \"syringe\",\n",
      "    \"846\": \"table lamp\",\n",
      "    \"847\": \"tank, army tank, armored combat vehicle, armoured combat vehicle\",\n",
      "    \"848\": \"tape player\",\n",
      "    \"849\": \"teapot\",\n",
      "    \"850\": \"teddy, teddy bear\",\n",
      "    \"851\": \"television, television system\",\n",
      "    \"852\": \"tennis ball\",\n",
      "    \"853\": \"thatch, thatched roof\",\n",
      "    \"854\": \"theater curtain, theatre curtain\",\n",
      "    \"855\": \"thimble\",\n",
      "    \"856\": \"thresher, thrasher, threshing machine\",\n",
      "    \"857\": \"throne\",\n",
      "    \"858\": \"tile roof\",\n",
      "    \"859\": \"toaster\",\n",
      "    \"860\": \"tobacco shop, tobacconist shop, tobacconist\",\n",
      "    \"861\": \"toilet seat\",\n",
      "    \"862\": \"torch\",\n",
      "    \"863\": \"totem pole\",\n",
      "    \"864\": \"tow truck, tow car, wrecker\",\n",
      "    \"865\": \"toyshop\",\n",
      "    \"866\": \"tractor\",\n",
      "    \"867\": \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\",\n",
      "    \"868\": \"tray\",\n",
      "    \"869\": \"trench coat\",\n",
      "    \"870\": \"tricycle, trike, velocipede\",\n",
      "    \"871\": \"trimaran\",\n",
      "    \"872\": \"tripod\",\n",
      "    \"873\": \"triumphal arch\",\n",
      "    \"874\": \"trolleybus, trolley coach, trackless trolley\",\n",
      "    \"875\": \"trombone\",\n",
      "    \"876\": \"tub, vat\",\n",
      "    \"877\": \"turnstile\",\n",
      "    \"878\": \"typewriter keyboard\",\n",
      "    \"879\": \"umbrella\",\n",
      "    \"880\": \"unicycle, monocycle\",\n",
      "    \"881\": \"upright, upright piano\",\n",
      "    \"882\": \"vacuum, vacuum cleaner\",\n",
      "    \"883\": \"vase\",\n",
      "    \"884\": \"vault\",\n",
      "    \"885\": \"velvet\",\n",
      "    \"886\": \"vending machine\",\n",
      "    \"887\": \"vestment\",\n",
      "    \"888\": \"viaduct\",\n",
      "    \"889\": \"violin, fiddle\",\n",
      "    \"890\": \"volleyball\",\n",
      "    \"891\": \"waffle iron\",\n",
      "    \"892\": \"wall clock\",\n",
      "    \"893\": \"wallet, billfold, notecase, pocketbook\",\n",
      "    \"894\": \"wardrobe, closet, press\",\n",
      "    \"895\": \"warplane, military plane\",\n",
      "    \"896\": \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\",\n",
      "    \"897\": \"washer, automatic washer, washing machine\",\n",
      "    \"898\": \"water bottle\",\n",
      "    \"899\": \"water jug\",\n",
      "    \"900\": \"water tower\",\n",
      "    \"901\": \"whiskey jug\",\n",
      "    \"902\": \"whistle\",\n",
      "    \"903\": \"wig\",\n",
      "    \"904\": \"window screen\",\n",
      "    \"905\": \"window shade\",\n",
      "    \"906\": \"Windsor tie\",\n",
      "    \"907\": \"wine bottle\",\n",
      "    \"908\": \"wing\",\n",
      "    \"909\": \"wok\",\n",
      "    \"910\": \"wooden spoon\",\n",
      "    \"911\": \"wool, woolen, woollen\",\n",
      "    \"912\": \"worm fence, snake fence, snake-rail fence, Virginia fence\",\n",
      "    \"913\": \"wreck\",\n",
      "    \"914\": \"yawl\",\n",
      "    \"915\": \"yurt\",\n",
      "    \"916\": \"web site, website, internet site, site\",\n",
      "    \"917\": \"comic book\",\n",
      "    \"918\": \"crossword puzzle, crossword\",\n",
      "    \"919\": \"street sign\",\n",
      "    \"920\": \"traffic light, traffic signal, stoplight\",\n",
      "    \"921\": \"book jacket, dust cover, dust jacket, dust wrapper\",\n",
      "    \"922\": \"menu\",\n",
      "    \"923\": \"plate\",\n",
      "    \"924\": \"guacamole\",\n",
      "    \"925\": \"consomme\",\n",
      "    \"926\": \"hot pot, hotpot\",\n",
      "    \"927\": \"trifle\",\n",
      "    \"928\": \"ice cream, icecream\",\n",
      "    \"929\": \"ice lolly, lolly, lollipop, popsicle\",\n",
      "    \"930\": \"French loaf\",\n",
      "    \"931\": \"bagel, beigel\",\n",
      "    \"932\": \"pretzel\",\n",
      "    \"933\": \"cheeseburger\",\n",
      "    \"934\": \"hotdog, hot dog, red hot\",\n",
      "    \"935\": \"mashed potato\",\n",
      "    \"936\": \"head cabbage\",\n",
      "    \"937\": \"broccoli\",\n",
      "    \"938\": \"cauliflower\",\n",
      "    \"939\": \"zucchini, courgette\",\n",
      "    \"940\": \"spaghetti squash\",\n",
      "    \"941\": \"acorn squash\",\n",
      "    \"942\": \"butternut squash\",\n",
      "    \"943\": \"cucumber, cuke\",\n",
      "    \"944\": \"artichoke, globe artichoke\",\n",
      "    \"945\": \"bell pepper\",\n",
      "    \"946\": \"cardoon\",\n",
      "    \"947\": \"mushroom\",\n",
      "    \"948\": \"Granny Smith\",\n",
      "    \"949\": \"strawberry\",\n",
      "    \"950\": \"orange\",\n",
      "    \"951\": \"lemon\",\n",
      "    \"952\": \"fig\",\n",
      "    \"953\": \"pineapple, ananas\",\n",
      "    \"954\": \"banana\",\n",
      "    \"955\": \"jackfruit, jak, jack\",\n",
      "    \"956\": \"custard apple\",\n",
      "    \"957\": \"pomegranate\",\n",
      "    \"958\": \"hay\",\n",
      "    \"959\": \"carbonara\",\n",
      "    \"960\": \"chocolate sauce, chocolate syrup\",\n",
      "    \"961\": \"dough\",\n",
      "    \"962\": \"meat loaf, meatloaf\",\n",
      "    \"963\": \"pizza, pizza pie\",\n",
      "    \"964\": \"potpie\",\n",
      "    \"965\": \"burrito\",\n",
      "    \"966\": \"red wine\",\n",
      "    \"967\": \"espresso\",\n",
      "    \"968\": \"cup\",\n",
      "    \"969\": \"eggnog\",\n",
      "    \"970\": \"alp\",\n",
      "    \"971\": \"bubble\",\n",
      "    \"972\": \"cliff, drop, drop-off\",\n",
      "    \"973\": \"coral reef\",\n",
      "    \"974\": \"geyser\",\n",
      "    \"975\": \"lakeside, lakeshore\",\n",
      "    \"976\": \"promontory, headland, head, foreland\",\n",
      "    \"977\": \"sandbar, sand bar\",\n",
      "    \"978\": \"seashore, coast, seacoast, sea-coast\",\n",
      "    \"979\": \"valley, vale\",\n",
      "    \"980\": \"volcano\",\n",
      "    \"981\": \"ballplayer, baseball player\",\n",
      "    \"982\": \"groom, bridegroom\",\n",
      "    \"983\": \"scuba diver\",\n",
      "    \"984\": \"rapeseed\",\n",
      "    \"985\": \"daisy\",\n",
      "    \"986\": \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\",\n",
      "    \"987\": \"corn\",\n",
      "    \"988\": \"acorn\",\n",
      "    \"989\": \"hip, rose hip, rosehip\",\n",
      "    \"990\": \"buckeye, horse chestnut, conker\",\n",
      "    \"991\": \"coral fungus\",\n",
      "    \"992\": \"agaric\",\n",
      "    \"993\": \"gyromitra\",\n",
      "    \"994\": \"stinkhorn, carrion fungus\",\n",
      "    \"995\": \"earthstar\",\n",
      "    \"996\": \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\",\n",
      "    \"997\": \"bolete\",\n",
      "    \"998\": \"ear, spike, capitulum\",\n",
      "    \"999\": \"toilet tissue, toilet paper, bathroom tissue\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Afghan hound, Afghan\": 160,\n",
      "    \"African chameleon, Chamaeleo chamaeleon\": 47,\n",
      "    \"African crocodile, Nile crocodile, Crocodylus niloticus\": 49,\n",
      "    \"African elephant, Loxodonta africana\": 386,\n",
      "    \"African grey, African gray, Psittacus erithacus\": 87,\n",
      "    \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\": 275,\n",
      "    \"Airedale, Airedale terrier\": 191,\n",
      "    \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\": 180,\n",
      "    \"American alligator, Alligator mississipiensis\": 50,\n",
      "    \"American black bear, black bear, Ursus americanus, Euarctos americanus\": 295,\n",
      "    \"American chameleon, anole, Anolis carolinensis\": 40,\n",
      "    \"American coot, marsh hen, mud hen, water hen, Fulica americana\": 137,\n",
      "    \"American egret, great white heron, Egretta albus\": 132,\n",
      "    \"American lobster, Northern lobster, Maine lobster, Homarus americanus\": 122,\n",
      "    \"Angora, Angora rabbit\": 332,\n",
      "    \"Appenzeller\": 240,\n",
      "    \"Arabian camel, dromedary, Camelus dromedarius\": 354,\n",
      "    \"Arctic fox, white fox, Alopex lagopus\": 279,\n",
      "    \"Australian terrier\": 193,\n",
      "    \"Band Aid\": 419,\n",
      "    \"Bedlington terrier\": 181,\n",
      "    \"Bernese mountain dog\": 239,\n",
      "    \"Blenheim spaniel\": 156,\n",
      "    \"Border collie\": 232,\n",
      "    \"Border terrier\": 182,\n",
      "    \"Boston bull, Boston terrier\": 195,\n",
      "    \"Bouvier des Flandres, Bouviers des Flandres\": 233,\n",
      "    \"Brabancon griffon\": 262,\n",
      "    \"Brittany spaniel\": 215,\n",
      "    \"CD player\": 485,\n",
      "    \"Cardigan, Cardigan Welsh corgi\": 264,\n",
      "    \"Chesapeake Bay retriever\": 209,\n",
      "    \"Chihuahua\": 151,\n",
      "    \"Christmas stocking\": 496,\n",
      "    \"Crock Pot\": 521,\n",
      "    \"Dandie Dinmont, Dandie Dinmont terrier\": 194,\n",
      "    \"Doberman, Doberman pinscher\": 236,\n",
      "    \"Dungeness crab, Cancer magister\": 118,\n",
      "    \"Dutch oven\": 544,\n",
      "    \"Egyptian cat\": 285,\n",
      "    \"English foxhound\": 167,\n",
      "    \"English setter\": 212,\n",
      "    \"English springer, English springer spaniel\": 217,\n",
      "    \"EntleBucher\": 241,\n",
      "    \"Eskimo dog, husky\": 248,\n",
      "    \"European fire salamander, Salamandra salamandra\": 25,\n",
      "    \"European gallinule, Porphyrio porphyrio\": 136,\n",
      "    \"French bulldog\": 245,\n",
      "    \"French horn, horn\": 566,\n",
      "    \"French loaf\": 930,\n",
      "    \"German shepherd, German shepherd dog, German police dog, alsatian\": 235,\n",
      "    \"German short-haired pointer\": 210,\n",
      "    \"Gila monster, Heloderma suspectum\": 45,\n",
      "    \"Gordon setter\": 214,\n",
      "    \"Granny Smith\": 948,\n",
      "    \"Great Dane\": 246,\n",
      "    \"Great Pyrenees\": 257,\n",
      "    \"Greater Swiss Mountain dog\": 238,\n",
      "    \"Ibizan hound, Ibizan Podenco\": 173,\n",
      "    \"Indian cobra, Naja naja\": 63,\n",
      "    \"Indian elephant, Elephas maximus\": 385,\n",
      "    \"Irish setter, red setter\": 213,\n",
      "    \"Irish terrier\": 184,\n",
      "    \"Irish water spaniel\": 221,\n",
      "    \"Irish wolfhound\": 170,\n",
      "    \"Italian greyhound\": 171,\n",
      "    \"Japanese spaniel\": 152,\n",
      "    \"Kerry blue terrier\": 183,\n",
      "    \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\": 48,\n",
      "    \"Labrador retriever\": 208,\n",
      "    \"Lakeland terrier\": 189,\n",
      "    \"Leonberg\": 255,\n",
      "    \"Lhasa, Lhasa apso\": 204,\n",
      "    \"Loafer\": 630,\n",
      "    \"Madagascar cat, ring-tailed lemur, Lemur catta\": 383,\n",
      "    \"Maltese dog, Maltese terrier, Maltese\": 153,\n",
      "    \"Mexican hairless\": 268,\n",
      "    \"Model T\": 661,\n",
      "    \"Newfoundland, Newfoundland dog\": 256,\n",
      "    \"Norfolk terrier\": 185,\n",
      "    \"Norwegian elkhound, elkhound\": 174,\n",
      "    \"Norwich terrier\": 186,\n",
      "    \"Old English sheepdog, bobtail\": 229,\n",
      "    \"Pekinese, Pekingese, Peke\": 154,\n",
      "    \"Pembroke, Pembroke Welsh corgi\": 263,\n",
      "    \"Persian cat\": 283,\n",
      "    \"Petri dish\": 712,\n",
      "    \"Polaroid camera, Polaroid Land camera\": 732,\n",
      "    \"Pomeranian\": 259,\n",
      "    \"Rhodesian ridgeback\": 159,\n",
      "    \"Rottweiler\": 234,\n",
      "    \"Saint Bernard, St Bernard\": 247,\n",
      "    \"Saluki, gazelle hound\": 176,\n",
      "    \"Samoyed, Samoyede\": 258,\n",
      "    \"Scotch terrier, Scottish terrier, Scottie\": 199,\n",
      "    \"Scottish deerhound, deerhound\": 177,\n",
      "    \"Sealyham terrier, Sealyham\": 190,\n",
      "    \"Shetland sheepdog, Shetland sheep dog, Shetland\": 230,\n",
      "    \"Shih-Tzu\": 155,\n",
      "    \"Siamese cat, Siamese\": 284,\n",
      "    \"Siberian husky\": 250,\n",
      "    \"Staffordshire bullterrier, Staffordshire bull terrier\": 179,\n",
      "    \"Sussex spaniel\": 220,\n",
      "    \"Tibetan mastiff\": 244,\n",
      "    \"Tibetan terrier, chrysanthemum dog\": 200,\n",
      "    \"Walker hound, Walker foxhound\": 166,\n",
      "    \"Weimaraner\": 178,\n",
      "    \"Welsh springer spaniel\": 218,\n",
      "    \"West Highland white terrier\": 203,\n",
      "    \"Windsor tie\": 906,\n",
      "    \"Yorkshire terrier\": 187,\n",
      "    \"abacus\": 398,\n",
      "    \"abaya\": 399,\n",
      "    \"academic gown, academic robe, judge's robe\": 400,\n",
      "    \"accordion, piano accordion, squeeze box\": 401,\n",
      "    \"acorn\": 988,\n",
      "    \"acorn squash\": 941,\n",
      "    \"acoustic guitar\": 402,\n",
      "    \"admiral\": 321,\n",
      "    \"affenpinscher, monkey pinscher, monkey dog\": 252,\n",
      "    \"agama\": 42,\n",
      "    \"agaric\": 992,\n",
      "    \"aircraft carrier, carrier, flattop, attack aircraft carrier\": 403,\n",
      "    \"airliner\": 404,\n",
      "    \"airship, dirigible\": 405,\n",
      "    \"albatross, mollymawk\": 146,\n",
      "    \"alligator lizard\": 44,\n",
      "    \"alp\": 970,\n",
      "    \"altar\": 406,\n",
      "    \"ambulance\": 407,\n",
      "    \"amphibian, amphibious vehicle\": 408,\n",
      "    \"analog clock\": 409,\n",
      "    \"anemone fish\": 393,\n",
      "    \"ant, emmet, pismire\": 310,\n",
      "    \"apiary, bee house\": 410,\n",
      "    \"apron\": 411,\n",
      "    \"armadillo\": 363,\n",
      "    \"artichoke, globe artichoke\": 944,\n",
      "    \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\": 412,\n",
      "    \"assault rifle, assault gun\": 413,\n",
      "    \"axolotl, mud puppy, Ambystoma mexicanum\": 29,\n",
      "    \"baboon\": 372,\n",
      "    \"backpack, back pack, knapsack, packsack, rucksack, haversack\": 414,\n",
      "    \"badger\": 362,\n",
      "    \"bagel, beigel\": 931,\n",
      "    \"bakery, bakeshop, bakehouse\": 415,\n",
      "    \"balance beam, beam\": 416,\n",
      "    \"bald eagle, American eagle, Haliaeetus leucocephalus\": 22,\n",
      "    \"balloon\": 417,\n",
      "    \"ballplayer, baseball player\": 981,\n",
      "    \"ballpoint, ballpoint pen, ballpen, Biro\": 418,\n",
      "    \"banana\": 954,\n",
      "    \"banded gecko\": 38,\n",
      "    \"banjo\": 420,\n",
      "    \"bannister, banister, balustrade, balusters, handrail\": 421,\n",
      "    \"barbell\": 422,\n",
      "    \"barber chair\": 423,\n",
      "    \"barbershop\": 424,\n",
      "    \"barn\": 425,\n",
      "    \"barn spider, Araneus cavaticus\": 73,\n",
      "    \"barometer\": 426,\n",
      "    \"barracouta, snoek\": 389,\n",
      "    \"barrel, cask\": 427,\n",
      "    \"barrow, garden cart, lawn cart, wheelbarrow\": 428,\n",
      "    \"baseball\": 429,\n",
      "    \"basenji\": 253,\n",
      "    \"basketball\": 430,\n",
      "    \"basset, basset hound\": 161,\n",
      "    \"bassinet\": 431,\n",
      "    \"bassoon\": 432,\n",
      "    \"bath towel\": 434,\n",
      "    \"bathing cap, swimming cap\": 433,\n",
      "    \"bathtub, bathing tub, bath, tub\": 435,\n",
      "    \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\": 436,\n",
      "    \"beacon, lighthouse, beacon light, pharos\": 437,\n",
      "    \"beagle\": 162,\n",
      "    \"beaker\": 438,\n",
      "    \"bearskin, busby, shako\": 439,\n",
      "    \"beaver\": 337,\n",
      "    \"bee\": 309,\n",
      "    \"bee eater\": 92,\n",
      "    \"beer bottle\": 440,\n",
      "    \"beer glass\": 441,\n",
      "    \"bell cote, bell cot\": 442,\n",
      "    \"bell pepper\": 945,\n",
      "    \"bib\": 443,\n",
      "    \"bicycle-built-for-two, tandem bicycle, tandem\": 444,\n",
      "    \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\": 349,\n",
      "    \"bikini, two-piece\": 445,\n",
      "    \"binder, ring-binder\": 446,\n",
      "    \"binoculars, field glasses, opera glasses\": 447,\n",
      "    \"birdhouse\": 448,\n",
      "    \"bison\": 347,\n",
      "    \"bittern\": 133,\n",
      "    \"black and gold garden spider, Argiope aurantia\": 72,\n",
      "    \"black grouse\": 80,\n",
      "    \"black stork, Ciconia nigra\": 128,\n",
      "    \"black swan, Cygnus atratus\": 100,\n",
      "    \"black widow, Latrodectus mactans\": 75,\n",
      "    \"black-and-tan coonhound\": 165,\n",
      "    \"black-footed ferret, ferret, Mustela nigripes\": 359,\n",
      "    \"bloodhound, sleuthhound\": 163,\n",
      "    \"bluetick\": 164,\n",
      "    \"boa constrictor, Constrictor constrictor\": 61,\n",
      "    \"boathouse\": 449,\n",
      "    \"bobsled, bobsleigh, bob\": 450,\n",
      "    \"bolete\": 997,\n",
      "    \"bolo tie, bolo, bola tie, bola\": 451,\n",
      "    \"bonnet, poke bonnet\": 452,\n",
      "    \"book jacket, dust cover, dust jacket, dust wrapper\": 921,\n",
      "    \"bookcase\": 453,\n",
      "    \"bookshop, bookstore, bookstall\": 454,\n",
      "    \"borzoi, Russian wolfhound\": 169,\n",
      "    \"bottlecap\": 455,\n",
      "    \"bow\": 456,\n",
      "    \"bow tie, bow-tie, bowtie\": 457,\n",
      "    \"box turtle, box tortoise\": 37,\n",
      "    \"boxer\": 242,\n",
      "    \"brain coral\": 109,\n",
      "    \"brambling, Fringilla montifringilla\": 10,\n",
      "    \"brass, memorial tablet, plaque\": 458,\n",
      "    \"brassiere, bra, bandeau\": 459,\n",
      "    \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\": 460,\n",
      "    \"breastplate, aegis, egis\": 461,\n",
      "    \"briard\": 226,\n",
      "    \"broccoli\": 937,\n",
      "    \"broom\": 462,\n",
      "    \"brown bear, bruin, Ursus arctos\": 294,\n",
      "    \"bubble\": 971,\n",
      "    \"bucket, pail\": 463,\n",
      "    \"buckeye, horse chestnut, conker\": 990,\n",
      "    \"buckle\": 464,\n",
      "    \"bulbul\": 16,\n",
      "    \"bull mastiff\": 243,\n",
      "    \"bullet train, bullet\": 466,\n",
      "    \"bulletproof vest\": 465,\n",
      "    \"bullfrog, Rana catesbeiana\": 30,\n",
      "    \"burrito\": 965,\n",
      "    \"bustard\": 138,\n",
      "    \"butcher shop, meat market\": 467,\n",
      "    \"butternut squash\": 942,\n",
      "    \"cab, hack, taxi, taxicab\": 468,\n",
      "    \"cabbage butterfly\": 324,\n",
      "    \"cairn, cairn terrier\": 192,\n",
      "    \"caldron, cauldron\": 469,\n",
      "    \"can opener, tin opener\": 473,\n",
      "    \"candle, taper, wax light\": 470,\n",
      "    \"cannon\": 471,\n",
      "    \"canoe\": 472,\n",
      "    \"capuchin, ringtail, Cebus capucinus\": 378,\n",
      "    \"car mirror\": 475,\n",
      "    \"car wheel\": 479,\n",
      "    \"carbonara\": 959,\n",
      "    \"cardigan\": 474,\n",
      "    \"cardoon\": 946,\n",
      "    \"carousel, carrousel, merry-go-round, roundabout, whirligig\": 476,\n",
      "    \"carpenter's kit, tool kit\": 477,\n",
      "    \"carton\": 478,\n",
      "    \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\": 480,\n",
      "    \"cassette\": 481,\n",
      "    \"cassette player\": 482,\n",
      "    \"castle\": 483,\n",
      "    \"catamaran\": 484,\n",
      "    \"cauliflower\": 938,\n",
      "    \"cello, violoncello\": 486,\n",
      "    \"cellular telephone, cellular phone, cellphone, cell, mobile phone\": 487,\n",
      "    \"centipede\": 79,\n",
      "    \"chain\": 488,\n",
      "    \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\": 490,\n",
      "    \"chain saw, chainsaw\": 491,\n",
      "    \"chainlink fence\": 489,\n",
      "    \"chambered nautilus, pearly nautilus, nautilus\": 117,\n",
      "    \"cheeseburger\": 933,\n",
      "    \"cheetah, chetah, Acinonyx jubatus\": 293,\n",
      "    \"chest\": 492,\n",
      "    \"chickadee\": 19,\n",
      "    \"chiffonier, commode\": 493,\n",
      "    \"chime, bell, gong\": 494,\n",
      "    \"chimpanzee, chimp, Pan troglodytes\": 367,\n",
      "    \"china cabinet, china closet\": 495,\n",
      "    \"chiton, coat-of-mail shell, sea cradle, polyplacophore\": 116,\n",
      "    \"chocolate sauce, chocolate syrup\": 960,\n",
      "    \"chow, chow chow\": 260,\n",
      "    \"church, church building\": 497,\n",
      "    \"cicada, cicala\": 316,\n",
      "    \"cinema, movie theater, movie theatre, movie house, picture palace\": 498,\n",
      "    \"cleaver, meat cleaver, chopper\": 499,\n",
      "    \"cliff dwelling\": 500,\n",
      "    \"cliff, drop, drop-off\": 972,\n",
      "    \"cloak\": 501,\n",
      "    \"clog, geta, patten, sabot\": 502,\n",
      "    \"clumber, clumber spaniel\": 216,\n",
      "    \"cock\": 7,\n",
      "    \"cocker spaniel, English cocker spaniel, cocker\": 219,\n",
      "    \"cockroach, roach\": 314,\n",
      "    \"cocktail shaker\": 503,\n",
      "    \"coffee mug\": 504,\n",
      "    \"coffeepot\": 505,\n",
      "    \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\": 391,\n",
      "    \"coil, spiral, volute, whorl, helix\": 506,\n",
      "    \"collie\": 231,\n",
      "    \"colobus, colobus monkey\": 375,\n",
      "    \"combination lock\": 507,\n",
      "    \"comic book\": 917,\n",
      "    \"common iguana, iguana, Iguana iguana\": 39,\n",
      "    \"common newt, Triturus vulgaris\": 26,\n",
      "    \"computer keyboard, keypad\": 508,\n",
      "    \"conch\": 112,\n",
      "    \"confectionery, confectionary, candy store\": 509,\n",
      "    \"consomme\": 925,\n",
      "    \"container ship, containership, container vessel\": 510,\n",
      "    \"convertible\": 511,\n",
      "    \"coral fungus\": 991,\n",
      "    \"coral reef\": 973,\n",
      "    \"corkscrew, bottle screw\": 512,\n",
      "    \"corn\": 987,\n",
      "    \"cornet, horn, trumpet, trump\": 513,\n",
      "    \"coucal\": 91,\n",
      "    \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\": 286,\n",
      "    \"cowboy boot\": 514,\n",
      "    \"cowboy hat, ten-gallon hat\": 515,\n",
      "    \"coyote, prairie wolf, brush wolf, Canis latrans\": 272,\n",
      "    \"cradle\": 516,\n",
      "    \"crane\": 517,\n",
      "    \"crash helmet\": 518,\n",
      "    \"crate\": 519,\n",
      "    \"crayfish, crawfish, crawdad, crawdaddy\": 124,\n",
      "    \"crib, cot\": 520,\n",
      "    \"cricket\": 312,\n",
      "    \"croquet ball\": 522,\n",
      "    \"crossword puzzle, crossword\": 918,\n",
      "    \"crutch\": 523,\n",
      "    \"cucumber, cuke\": 943,\n",
      "    \"cuirass\": 524,\n",
      "    \"cup\": 968,\n",
      "    \"curly-coated retriever\": 206,\n",
      "    \"custard apple\": 956,\n",
      "    \"daisy\": 985,\n",
      "    \"dalmatian, coach dog, carriage dog\": 251,\n",
      "    \"dam, dike, dyke\": 525,\n",
      "    \"damselfly\": 320,\n",
      "    \"desk\": 526,\n",
      "    \"desktop computer\": 527,\n",
      "    \"dhole, Cuon alpinus\": 274,\n",
      "    \"dial telephone, dial phone\": 528,\n",
      "    \"diamondback, diamondback rattlesnake, Crotalus adamanteus\": 67,\n",
      "    \"diaper, nappy, napkin\": 529,\n",
      "    \"digital clock\": 530,\n",
      "    \"digital watch\": 531,\n",
      "    \"dingo, warrigal, warragal, Canis dingo\": 273,\n",
      "    \"dining table, board\": 532,\n",
      "    \"dishrag, dishcloth\": 533,\n",
      "    \"dishwasher, dish washer, dishwashing machine\": 534,\n",
      "    \"disk brake, disc brake\": 535,\n",
      "    \"dock, dockage, docking facility\": 536,\n",
      "    \"dogsled, dog sled, dog sleigh\": 537,\n",
      "    \"dome\": 538,\n",
      "    \"doormat, welcome mat\": 539,\n",
      "    \"dough\": 961,\n",
      "    \"dowitcher\": 142,\n",
      "    \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\": 319,\n",
      "    \"drake\": 97,\n",
      "    \"drilling platform, offshore rig\": 540,\n",
      "    \"drum, membranophone, tympan\": 541,\n",
      "    \"drumstick\": 542,\n",
      "    \"dugong, Dugong dugon\": 149,\n",
      "    \"dumbbell\": 543,\n",
      "    \"dung beetle\": 305,\n",
      "    \"ear, spike, capitulum\": 998,\n",
      "    \"earthstar\": 995,\n",
      "    \"echidna, spiny anteater, anteater\": 102,\n",
      "    \"eel\": 390,\n",
      "    \"eft\": 27,\n",
      "    \"eggnog\": 969,\n",
      "    \"electric fan, blower\": 545,\n",
      "    \"electric guitar\": 546,\n",
      "    \"electric locomotive\": 547,\n",
      "    \"electric ray, crampfish, numbfish, torpedo\": 5,\n",
      "    \"entertainment center\": 548,\n",
      "    \"envelope\": 549,\n",
      "    \"espresso\": 967,\n",
      "    \"espresso maker\": 550,\n",
      "    \"face powder\": 551,\n",
      "    \"feather boa, boa\": 552,\n",
      "    \"fiddler crab\": 120,\n",
      "    \"fig\": 952,\n",
      "    \"file, file cabinet, filing cabinet\": 553,\n",
      "    \"fire engine, fire truck\": 555,\n",
      "    \"fire screen, fireguard\": 556,\n",
      "    \"fireboat\": 554,\n",
      "    \"flagpole, flagstaff\": 557,\n",
      "    \"flamingo\": 130,\n",
      "    \"flat-coated retriever\": 205,\n",
      "    \"flatworm, platyhelminth\": 110,\n",
      "    \"flute, transverse flute\": 558,\n",
      "    \"fly\": 308,\n",
      "    \"folding chair\": 559,\n",
      "    \"football helmet\": 560,\n",
      "    \"forklift\": 561,\n",
      "    \"fountain\": 562,\n",
      "    \"fountain pen\": 563,\n",
      "    \"four-poster\": 564,\n",
      "    \"fox squirrel, eastern fox squirrel, Sciurus niger\": 335,\n",
      "    \"freight car\": 565,\n",
      "    \"frilled lizard, Chlamydosaurus kingi\": 43,\n",
      "    \"frying pan, frypan, skillet\": 567,\n",
      "    \"fur coat\": 568,\n",
      "    \"gar, garfish, garpike, billfish, Lepisosteus osseus\": 395,\n",
      "    \"garbage truck, dustcart\": 569,\n",
      "    \"garden spider, Aranea diademata\": 74,\n",
      "    \"garter snake, grass snake\": 57,\n",
      "    \"gas pump, gasoline pump, petrol pump, island dispenser\": 571,\n",
      "    \"gasmask, respirator, gas helmet\": 570,\n",
      "    \"gazelle\": 353,\n",
      "    \"geyser\": 974,\n",
      "    \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\": 388,\n",
      "    \"giant schnauzer\": 197,\n",
      "    \"gibbon, Hylobates lar\": 368,\n",
      "    \"go-kart\": 573,\n",
      "    \"goblet\": 572,\n",
      "    \"golden retriever\": 207,\n",
      "    \"goldfinch, Carduelis carduelis\": 11,\n",
      "    \"goldfish, Carassius auratus\": 1,\n",
      "    \"golf ball\": 574,\n",
      "    \"golfcart, golf cart\": 575,\n",
      "    \"gondola\": 576,\n",
      "    \"gong, tam-tam\": 577,\n",
      "    \"goose\": 99,\n",
      "    \"gorilla, Gorilla gorilla\": 366,\n",
      "    \"gown\": 578,\n",
      "    \"grand piano, grand\": 579,\n",
      "    \"grasshopper, hopper\": 311,\n",
      "    \"great grey owl, great gray owl, Strix nebulosa\": 24,\n",
      "    \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\": 2,\n",
      "    \"green lizard, Lacerta viridis\": 46,\n",
      "    \"green mamba\": 64,\n",
      "    \"green snake, grass snake\": 55,\n",
      "    \"greenhouse, nursery, glasshouse\": 580,\n",
      "    \"grey fox, gray fox, Urocyon cinereoargenteus\": 280,\n",
      "    \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\": 147,\n",
      "    \"grille, radiator grille\": 581,\n",
      "    \"grocery store, grocery, food market, market\": 582,\n",
      "    \"groenendael\": 224,\n",
      "    \"groom, bridegroom\": 982,\n",
      "    \"ground beetle, carabid beetle\": 302,\n",
      "    \"guacamole\": 924,\n",
      "    \"guenon, guenon monkey\": 370,\n",
      "    \"guillotine\": 583,\n",
      "    \"guinea pig, Cavia cobaya\": 338,\n",
      "    \"gyromitra\": 993,\n",
      "    \"hair slide\": 584,\n",
      "    \"hair spray\": 585,\n",
      "    \"half track\": 586,\n",
      "    \"hammer\": 587,\n",
      "    \"hammerhead, hammerhead shark\": 4,\n",
      "    \"hamper\": 588,\n",
      "    \"hamster\": 333,\n",
      "    \"hand blower, blow dryer, blow drier, hair dryer, hair drier\": 589,\n",
      "    \"hand-held computer, hand-held microcomputer\": 590,\n",
      "    \"handkerchief, hankie, hanky, hankey\": 591,\n",
      "    \"hard disc, hard disk, fixed disk\": 592,\n",
      "    \"hare\": 331,\n",
      "    \"harmonica, mouth organ, harp, mouth harp\": 593,\n",
      "    \"harp\": 594,\n",
      "    \"hartebeest\": 351,\n",
      "    \"harvester, reaper\": 595,\n",
      "    \"harvestman, daddy longlegs, Phalangium opilio\": 70,\n",
      "    \"hatchet\": 596,\n",
      "    \"hay\": 958,\n",
      "    \"head cabbage\": 936,\n",
      "    \"hen\": 8,\n",
      "    \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\": 996,\n",
      "    \"hermit crab\": 125,\n",
      "    \"hip, rose hip, rosehip\": 989,\n",
      "    \"hippopotamus, hippo, river horse, Hippopotamus amphibius\": 344,\n",
      "    \"hog, pig, grunter, squealer, Sus scrofa\": 341,\n",
      "    \"hognose snake, puff adder, sand viper\": 54,\n",
      "    \"holster\": 597,\n",
      "    \"home theater, home theatre\": 598,\n",
      "    \"honeycomb\": 599,\n",
      "    \"hook, claw\": 600,\n",
      "    \"hoopskirt, crinoline\": 601,\n",
      "    \"horizontal bar, high bar\": 602,\n",
      "    \"hornbill\": 93,\n",
      "    \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\": 66,\n",
      "    \"horse cart, horse-cart\": 603,\n",
      "    \"hot pot, hotpot\": 926,\n",
      "    \"hotdog, hot dog, red hot\": 934,\n",
      "    \"hourglass\": 604,\n",
      "    \"house finch, linnet, Carpodacus mexicanus\": 12,\n",
      "    \"howler monkey, howler\": 379,\n",
      "    \"hummingbird\": 94,\n",
      "    \"hyena, hyaena\": 276,\n",
      "    \"iPod\": 605,\n",
      "    \"ibex, Capra ibex\": 350,\n",
      "    \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\": 296,\n",
      "    \"ice cream, icecream\": 928,\n",
      "    \"ice lolly, lolly, lollipop, popsicle\": 929,\n",
      "    \"impala, Aepyceros melampus\": 352,\n",
      "    \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\": 14,\n",
      "    \"indri, indris, Indri indri, Indri brevicaudatus\": 384,\n",
      "    \"iron, smoothing iron\": 606,\n",
      "    \"isopod\": 126,\n",
      "    \"jacamar\": 95,\n",
      "    \"jack-o'-lantern\": 607,\n",
      "    \"jackfruit, jak, jack\": 955,\n",
      "    \"jaguar, panther, Panthera onca, Felis onca\": 290,\n",
      "    \"jay\": 17,\n",
      "    \"jean, blue jean, denim\": 608,\n",
      "    \"jeep, landrover\": 609,\n",
      "    \"jellyfish\": 107,\n",
      "    \"jersey, T-shirt, tee shirt\": 610,\n",
      "    \"jigsaw puzzle\": 611,\n",
      "    \"jinrikisha, ricksha, rickshaw\": 612,\n",
      "    \"joystick\": 613,\n",
      "    \"junco, snowbird\": 13,\n",
      "    \"keeshond\": 261,\n",
      "    \"kelpie\": 227,\n",
      "    \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\": 148,\n",
      "    \"kimono\": 614,\n",
      "    \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\": 121,\n",
      "    \"king penguin, Aptenodytes patagonica\": 145,\n",
      "    \"king snake, kingsnake\": 56,\n",
      "    \"kit fox, Vulpes macrotis\": 278,\n",
      "    \"kite\": 21,\n",
      "    \"knee pad\": 615,\n",
      "    \"knot\": 616,\n",
      "    \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\": 105,\n",
      "    \"komondor\": 228,\n",
      "    \"kuvasz\": 222,\n",
      "    \"lab coat, laboratory coat\": 617,\n",
      "    \"lacewing, lacewing fly\": 318,\n",
      "    \"ladle\": 618,\n",
      "    \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\": 301,\n",
      "    \"lakeside, lakeshore\": 975,\n",
      "    \"lampshade, lamp shade\": 619,\n",
      "    \"langur\": 374,\n",
      "    \"laptop, laptop computer\": 620,\n",
      "    \"lawn mower, mower\": 621,\n",
      "    \"leaf beetle, chrysomelid\": 304,\n",
      "    \"leafhopper\": 317,\n",
      "    \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\": 34,\n",
      "    \"lemon\": 951,\n",
      "    \"lens cap, lens cover\": 622,\n",
      "    \"leopard, Panthera pardus\": 288,\n",
      "    \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\": 387,\n",
      "    \"letter opener, paper knife, paperknife\": 623,\n",
      "    \"library\": 624,\n",
      "    \"lifeboat\": 625,\n",
      "    \"lighter, light, igniter, ignitor\": 626,\n",
      "    \"limousine, limo\": 627,\n",
      "    \"limpkin, Aramus pictus\": 135,\n",
      "    \"liner, ocean liner\": 628,\n",
      "    \"lion, king of beasts, Panthera leo\": 291,\n",
      "    \"lionfish\": 396,\n",
      "    \"lipstick, lip rouge\": 629,\n",
      "    \"little blue heron, Egretta caerulea\": 131,\n",
      "    \"llama\": 355,\n",
      "    \"loggerhead, loggerhead turtle, Caretta caretta\": 33,\n",
      "    \"long-horned beetle, longicorn, longicorn beetle\": 303,\n",
      "    \"lorikeet\": 90,\n",
      "    \"lotion\": 631,\n",
      "    \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\": 632,\n",
      "    \"loupe, jeweler's loupe\": 633,\n",
      "    \"lumbermill, sawmill\": 634,\n",
      "    \"lycaenid, lycaenid butterfly\": 326,\n",
      "    \"lynx, catamount\": 287,\n",
      "    \"macaque\": 373,\n",
      "    \"macaw\": 88,\n",
      "    \"magnetic compass\": 635,\n",
      "    \"magpie\": 18,\n",
      "    \"mailbag, postbag\": 636,\n",
      "    \"mailbox, letter box\": 637,\n",
      "    \"maillot\": 638,\n",
      "    \"maillot, tank suit\": 639,\n",
      "    \"malamute, malemute, Alaskan malamute\": 249,\n",
      "    \"malinois\": 225,\n",
      "    \"manhole cover\": 640,\n",
      "    \"mantis, mantid\": 315,\n",
      "    \"maraca\": 641,\n",
      "    \"marimba, xylophone\": 642,\n",
      "    \"marmoset\": 377,\n",
      "    \"marmot\": 336,\n",
      "    \"mashed potato\": 935,\n",
      "    \"mask\": 643,\n",
      "    \"matchstick\": 644,\n",
      "    \"maypole\": 645,\n",
      "    \"maze, labyrinth\": 646,\n",
      "    \"measuring cup\": 647,\n",
      "    \"meat loaf, meatloaf\": 962,\n",
      "    \"medicine chest, medicine cabinet\": 648,\n",
      "    \"meerkat, mierkat\": 299,\n",
      "    \"megalith, megalithic structure\": 649,\n",
      "    \"menu\": 922,\n",
      "    \"microphone, mike\": 650,\n",
      "    \"microwave, microwave oven\": 651,\n",
      "    \"military uniform\": 652,\n",
      "    \"milk can\": 653,\n",
      "    \"miniature pinscher\": 237,\n",
      "    \"miniature poodle\": 266,\n",
      "    \"miniature schnauzer\": 196,\n",
      "    \"minibus\": 654,\n",
      "    \"miniskirt, mini\": 655,\n",
      "    \"minivan\": 656,\n",
      "    \"mink\": 357,\n",
      "    \"missile\": 657,\n",
      "    \"mitten\": 658,\n",
      "    \"mixing bowl\": 659,\n",
      "    \"mobile home, manufactured home\": 660,\n",
      "    \"modem\": 662,\n",
      "    \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\": 323,\n",
      "    \"monastery\": 663,\n",
      "    \"mongoose\": 298,\n",
      "    \"monitor\": 664,\n",
      "    \"moped\": 665,\n",
      "    \"mortar\": 666,\n",
      "    \"mortarboard\": 667,\n",
      "    \"mosque\": 668,\n",
      "    \"mosquito net\": 669,\n",
      "    \"motor scooter, scooter\": 670,\n",
      "    \"mountain bike, all-terrain bike, off-roader\": 671,\n",
      "    \"mountain tent\": 672,\n",
      "    \"mouse, computer mouse\": 673,\n",
      "    \"mousetrap\": 674,\n",
      "    \"moving van\": 675,\n",
      "    \"mud turtle\": 35,\n",
      "    \"mushroom\": 947,\n",
      "    \"muzzle\": 676,\n",
      "    \"nail\": 677,\n",
      "    \"neck brace\": 678,\n",
      "    \"necklace\": 679,\n",
      "    \"nematode, nematode worm, roundworm\": 111,\n",
      "    \"night snake, Hypsiglena torquata\": 60,\n",
      "    \"nipple\": 680,\n",
      "    \"notebook, notebook computer\": 681,\n",
      "    \"obelisk\": 682,\n",
      "    \"oboe, hautboy, hautbois\": 683,\n",
      "    \"ocarina, sweet potato\": 684,\n",
      "    \"odometer, hodometer, mileometer, milometer\": 685,\n",
      "    \"oil filter\": 686,\n",
      "    \"orange\": 950,\n",
      "    \"orangutan, orang, orangutang, Pongo pygmaeus\": 365,\n",
      "    \"organ, pipe organ\": 687,\n",
      "    \"oscilloscope, scope, cathode-ray oscilloscope, CRO\": 688,\n",
      "    \"ostrich, Struthio camelus\": 9,\n",
      "    \"otter\": 360,\n",
      "    \"otterhound, otter hound\": 175,\n",
      "    \"overskirt\": 689,\n",
      "    \"ox\": 345,\n",
      "    \"oxcart\": 690,\n",
      "    \"oxygen mask\": 691,\n",
      "    \"oystercatcher, oyster catcher\": 143,\n",
      "    \"packet\": 692,\n",
      "    \"paddle, boat paddle\": 693,\n",
      "    \"paddlewheel, paddle wheel\": 694,\n",
      "    \"padlock\": 695,\n",
      "    \"paintbrush\": 696,\n",
      "    \"pajama, pyjama, pj's, jammies\": 697,\n",
      "    \"palace\": 698,\n",
      "    \"panpipe, pandean pipe, syrinx\": 699,\n",
      "    \"paper towel\": 700,\n",
      "    \"papillon\": 157,\n",
      "    \"parachute, chute\": 701,\n",
      "    \"parallel bars, bars\": 702,\n",
      "    \"park bench\": 703,\n",
      "    \"parking meter\": 704,\n",
      "    \"partridge\": 86,\n",
      "    \"passenger car, coach, carriage\": 705,\n",
      "    \"patas, hussar monkey, Erythrocebus patas\": 371,\n",
      "    \"patio, terrace\": 706,\n",
      "    \"pay-phone, pay-station\": 707,\n",
      "    \"peacock\": 84,\n",
      "    \"pedestal, plinth, footstall\": 708,\n",
      "    \"pelican\": 144,\n",
      "    \"pencil box, pencil case\": 709,\n",
      "    \"pencil sharpener\": 710,\n",
      "    \"perfume, essence\": 711,\n",
      "    \"photocopier\": 713,\n",
      "    \"pick, plectrum, plectron\": 714,\n",
      "    \"pickelhaube\": 715,\n",
      "    \"picket fence, paling\": 716,\n",
      "    \"pickup, pickup truck\": 717,\n",
      "    \"pier\": 718,\n",
      "    \"piggy bank, penny bank\": 719,\n",
      "    \"pill bottle\": 720,\n",
      "    \"pillow\": 721,\n",
      "    \"pineapple, ananas\": 953,\n",
      "    \"ping-pong ball\": 722,\n",
      "    \"pinwheel\": 723,\n",
      "    \"pirate, pirate ship\": 724,\n",
      "    \"pitcher, ewer\": 725,\n",
      "    \"pizza, pizza pie\": 963,\n",
      "    \"plane, carpenter's plane, woodworking plane\": 726,\n",
      "    \"planetarium\": 727,\n",
      "    \"plastic bag\": 728,\n",
      "    \"plate\": 923,\n",
      "    \"plate rack\": 729,\n",
      "    \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\": 103,\n",
      "    \"plow, plough\": 730,\n",
      "    \"plunger, plumber's helper\": 731,\n",
      "    \"pole\": 733,\n",
      "    \"polecat, fitch, foulmart, foumart, Mustela putorius\": 358,\n",
      "    \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\": 734,\n",
      "    \"pomegranate\": 957,\n",
      "    \"poncho\": 735,\n",
      "    \"pool table, billiard table, snooker table\": 736,\n",
      "    \"pop bottle, soda bottle\": 737,\n",
      "    \"porcupine, hedgehog\": 334,\n",
      "    \"pot, flowerpot\": 738,\n",
      "    \"potpie\": 964,\n",
      "    \"potter's wheel\": 739,\n",
      "    \"power drill\": 740,\n",
      "    \"prairie chicken, prairie grouse, prairie fowl\": 83,\n",
      "    \"prayer rug, prayer mat\": 741,\n",
      "    \"pretzel\": 932,\n",
      "    \"printer\": 742,\n",
      "    \"prison, prison house\": 743,\n",
      "    \"proboscis monkey, Nasalis larvatus\": 376,\n",
      "    \"projectile, missile\": 744,\n",
      "    \"projector\": 745,\n",
      "    \"promontory, headland, head, foreland\": 976,\n",
      "    \"ptarmigan\": 81,\n",
      "    \"puck, hockey puck\": 746,\n",
      "    \"puffer, pufferfish, blowfish, globefish\": 397,\n",
      "    \"pug, pug-dog\": 254,\n",
      "    \"punching bag, punch bag, punching ball, punchball\": 747,\n",
      "    \"purse\": 748,\n",
      "    \"quail\": 85,\n",
      "    \"quill, quill pen\": 749,\n",
      "    \"quilt, comforter, comfort, puff\": 750,\n",
      "    \"racer, race car, racing car\": 751,\n",
      "    \"racket, racquet\": 752,\n",
      "    \"radiator\": 753,\n",
      "    \"radio telescope, radio reflector\": 755,\n",
      "    \"radio, wireless\": 754,\n",
      "    \"rain barrel\": 756,\n",
      "    \"ram, tup\": 348,\n",
      "    \"rapeseed\": 984,\n",
      "    \"recreational vehicle, RV, R.V.\": 757,\n",
      "    \"red fox, Vulpes vulpes\": 277,\n",
      "    \"red wine\": 966,\n",
      "    \"red wolf, maned wolf, Canis rufus, Canis niger\": 271,\n",
      "    \"red-backed sandpiper, dunlin, Erolia alpina\": 140,\n",
      "    \"red-breasted merganser, Mergus serrator\": 98,\n",
      "    \"redbone\": 168,\n",
      "    \"redshank, Tringa totanus\": 141,\n",
      "    \"reel\": 758,\n",
      "    \"reflex camera\": 759,\n",
      "    \"refrigerator, icebox\": 760,\n",
      "    \"remote control, remote\": 761,\n",
      "    \"restaurant, eating house, eating place, eatery\": 762,\n",
      "    \"revolver, six-gun, six-shooter\": 763,\n",
      "    \"rhinoceros beetle\": 306,\n",
      "    \"rifle\": 764,\n",
      "    \"ringlet, ringlet butterfly\": 322,\n",
      "    \"ringneck snake, ring-necked snake, ring snake\": 53,\n",
      "    \"robin, American robin, Turdus migratorius\": 15,\n",
      "    \"rock beauty, Holocanthus tricolor\": 392,\n",
      "    \"rock crab, Cancer irroratus\": 119,\n",
      "    \"rock python, rock snake, Python sebae\": 62,\n",
      "    \"rocking chair, rocker\": 765,\n",
      "    \"rotisserie\": 766,\n",
      "    \"rubber eraser, rubber, pencil eraser\": 767,\n",
      "    \"ruddy turnstone, Arenaria interpres\": 139,\n",
      "    \"ruffed grouse, partridge, Bonasa umbellus\": 82,\n",
      "    \"rugby ball\": 768,\n",
      "    \"rule, ruler\": 769,\n",
      "    \"running shoe\": 770,\n",
      "    \"safe\": 771,\n",
      "    \"safety pin\": 772,\n",
      "    \"saltshaker, salt shaker\": 773,\n",
      "    \"sandal\": 774,\n",
      "    \"sandbar, sand bar\": 977,\n",
      "    \"sarong\": 775,\n",
      "    \"sax, saxophone\": 776,\n",
      "    \"scabbard\": 777,\n",
      "    \"scale, weighing machine\": 778,\n",
      "    \"schipperke\": 223,\n",
      "    \"school bus\": 779,\n",
      "    \"schooner\": 780,\n",
      "    \"scoreboard\": 781,\n",
      "    \"scorpion\": 71,\n",
      "    \"screen, CRT screen\": 782,\n",
      "    \"screw\": 783,\n",
      "    \"screwdriver\": 784,\n",
      "    \"scuba diver\": 983,\n",
      "    \"sea anemone, anemone\": 108,\n",
      "    \"sea cucumber, holothurian\": 329,\n",
      "    \"sea lion\": 150,\n",
      "    \"sea slug, nudibranch\": 115,\n",
      "    \"sea snake\": 65,\n",
      "    \"sea urchin\": 328,\n",
      "    \"seashore, coast, seacoast, sea-coast\": 978,\n",
      "    \"seat belt, seatbelt\": 785,\n",
      "    \"sewing machine\": 786,\n",
      "    \"shield, buckler\": 787,\n",
      "    \"shoe shop, shoe-shop, shoe store\": 788,\n",
      "    \"shoji\": 789,\n",
      "    \"shopping basket\": 790,\n",
      "    \"shopping cart\": 791,\n",
      "    \"shovel\": 792,\n",
      "    \"shower cap\": 793,\n",
      "    \"shower curtain\": 794,\n",
      "    \"siamang, Hylobates syndactylus, Symphalangus syndactylus\": 369,\n",
      "    \"sidewinder, horned rattlesnake, Crotalus cerastes\": 68,\n",
      "    \"silky terrier, Sydney silky\": 201,\n",
      "    \"ski\": 795,\n",
      "    \"ski mask\": 796,\n",
      "    \"skunk, polecat, wood pussy\": 361,\n",
      "    \"sleeping bag\": 797,\n",
      "    \"slide rule, slipstick\": 798,\n",
      "    \"sliding door\": 799,\n",
      "    \"slot, one-armed bandit\": 800,\n",
      "    \"sloth bear, Melursus ursinus, Ursus ursinus\": 297,\n",
      "    \"slug\": 114,\n",
      "    \"snail\": 113,\n",
      "    \"snorkel\": 801,\n",
      "    \"snow leopard, ounce, Panthera uncia\": 289,\n",
      "    \"snowmobile\": 802,\n",
      "    \"snowplow, snowplough\": 803,\n",
      "    \"soap dispenser\": 804,\n",
      "    \"soccer ball\": 805,\n",
      "    \"sock\": 806,\n",
      "    \"soft-coated wheaten terrier\": 202,\n",
      "    \"solar dish, solar collector, solar furnace\": 807,\n",
      "    \"sombrero\": 808,\n",
      "    \"sorrel\": 339,\n",
      "    \"soup bowl\": 809,\n",
      "    \"space bar\": 810,\n",
      "    \"space heater\": 811,\n",
      "    \"space shuttle\": 812,\n",
      "    \"spaghetti squash\": 940,\n",
      "    \"spatula\": 813,\n",
      "    \"speedboat\": 814,\n",
      "    \"spider monkey, Ateles geoffroyi\": 381,\n",
      "    \"spider web, spider's web\": 815,\n",
      "    \"spindle\": 816,\n",
      "    \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\": 123,\n",
      "    \"spoonbill\": 129,\n",
      "    \"sports car, sport car\": 817,\n",
      "    \"spotlight, spot\": 818,\n",
      "    \"spotted salamander, Ambystoma maculatum\": 28,\n",
      "    \"squirrel monkey, Saimiri sciureus\": 382,\n",
      "    \"stage\": 819,\n",
      "    \"standard poodle\": 267,\n",
      "    \"standard schnauzer\": 198,\n",
      "    \"starfish, sea star\": 327,\n",
      "    \"steam locomotive\": 820,\n",
      "    \"steel arch bridge\": 821,\n",
      "    \"steel drum\": 822,\n",
      "    \"stethoscope\": 823,\n",
      "    \"stingray\": 6,\n",
      "    \"stinkhorn, carrion fungus\": 994,\n",
      "    \"stole\": 824,\n",
      "    \"stone wall\": 825,\n",
      "    \"stopwatch, stop watch\": 826,\n",
      "    \"stove\": 827,\n",
      "    \"strainer\": 828,\n",
      "    \"strawberry\": 949,\n",
      "    \"street sign\": 919,\n",
      "    \"streetcar, tram, tramcar, trolley, trolley car\": 829,\n",
      "    \"stretcher\": 830,\n",
      "    \"studio couch, day bed\": 831,\n",
      "    \"stupa, tope\": 832,\n",
      "    \"sturgeon\": 394,\n",
      "    \"submarine, pigboat, sub, U-boat\": 833,\n",
      "    \"suit, suit of clothes\": 834,\n",
      "    \"sulphur butterfly, sulfur butterfly\": 325,\n",
      "    \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\": 89,\n",
      "    \"sundial\": 835,\n",
      "    \"sunglass\": 836,\n",
      "    \"sunglasses, dark glasses, shades\": 837,\n",
      "    \"sunscreen, sunblock, sun blocker\": 838,\n",
      "    \"suspension bridge\": 839,\n",
      "    \"swab, swob, mop\": 840,\n",
      "    \"sweatshirt\": 841,\n",
      "    \"swimming trunks, bathing trunks\": 842,\n",
      "    \"swing\": 843,\n",
      "    \"switch, electric switch, electrical switch\": 844,\n",
      "    \"syringe\": 845,\n",
      "    \"tabby, tabby cat\": 281,\n",
      "    \"table lamp\": 846,\n",
      "    \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\": 32,\n",
      "    \"tank, army tank, armored combat vehicle, armoured combat vehicle\": 847,\n",
      "    \"tape player\": 848,\n",
      "    \"tarantula\": 76,\n",
      "    \"teapot\": 849,\n",
      "    \"teddy, teddy bear\": 850,\n",
      "    \"television, television system\": 851,\n",
      "    \"tench, Tinca tinca\": 0,\n",
      "    \"tennis ball\": 852,\n",
      "    \"terrapin\": 36,\n",
      "    \"thatch, thatched roof\": 853,\n",
      "    \"theater curtain, theatre curtain\": 854,\n",
      "    \"thimble\": 855,\n",
      "    \"three-toed sloth, ai, Bradypus tridactylus\": 364,\n",
      "    \"thresher, thrasher, threshing machine\": 856,\n",
      "    \"throne\": 857,\n",
      "    \"thunder snake, worm snake, Carphophis amoenus\": 52,\n",
      "    \"tick\": 78,\n",
      "    \"tiger beetle\": 300,\n",
      "    \"tiger cat\": 282,\n",
      "    \"tiger shark, Galeocerdo cuvieri\": 3,\n",
      "    \"tiger, Panthera tigris\": 292,\n",
      "    \"tile roof\": 858,\n",
      "    \"timber wolf, grey wolf, gray wolf, Canis lupus\": 269,\n",
      "    \"titi, titi monkey\": 380,\n",
      "    \"toaster\": 859,\n",
      "    \"tobacco shop, tobacconist shop, tobacconist\": 860,\n",
      "    \"toilet seat\": 861,\n",
      "    \"toilet tissue, toilet paper, bathroom tissue\": 999,\n",
      "    \"torch\": 862,\n",
      "    \"totem pole\": 863,\n",
      "    \"toucan\": 96,\n",
      "    \"tow truck, tow car, wrecker\": 864,\n",
      "    \"toy poodle\": 265,\n",
      "    \"toy terrier\": 158,\n",
      "    \"toyshop\": 865,\n",
      "    \"tractor\": 866,\n",
      "    \"traffic light, traffic signal, stoplight\": 920,\n",
      "    \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\": 867,\n",
      "    \"tray\": 868,\n",
      "    \"tree frog, tree-frog\": 31,\n",
      "    \"trench coat\": 869,\n",
      "    \"triceratops\": 51,\n",
      "    \"tricycle, trike, velocipede\": 870,\n",
      "    \"trifle\": 927,\n",
      "    \"trilobite\": 69,\n",
      "    \"trimaran\": 871,\n",
      "    \"tripod\": 872,\n",
      "    \"triumphal arch\": 873,\n",
      "    \"trolleybus, trolley coach, trackless trolley\": 874,\n",
      "    \"trombone\": 875,\n",
      "    \"tub, vat\": 876,\n",
      "    \"turnstile\": 877,\n",
      "    \"tusker\": 101,\n",
      "    \"typewriter keyboard\": 878,\n",
      "    \"umbrella\": 879,\n",
      "    \"unicycle, monocycle\": 880,\n",
      "    \"upright, upright piano\": 881,\n",
      "    \"vacuum, vacuum cleaner\": 882,\n",
      "    \"valley, vale\": 979,\n",
      "    \"vase\": 883,\n",
      "    \"vault\": 884,\n",
      "    \"velvet\": 885,\n",
      "    \"vending machine\": 886,\n",
      "    \"vestment\": 887,\n",
      "    \"viaduct\": 888,\n",
      "    \"vine snake\": 59,\n",
      "    \"violin, fiddle\": 889,\n",
      "    \"vizsla, Hungarian pointer\": 211,\n",
      "    \"volcano\": 980,\n",
      "    \"volleyball\": 890,\n",
      "    \"vulture\": 23,\n",
      "    \"waffle iron\": 891,\n",
      "    \"walking stick, walkingstick, stick insect\": 313,\n",
      "    \"wall clock\": 892,\n",
      "    \"wallaby, brush kangaroo\": 104,\n",
      "    \"wallet, billfold, notecase, pocketbook\": 893,\n",
      "    \"wardrobe, closet, press\": 894,\n",
      "    \"warplane, military plane\": 895,\n",
      "    \"warthog\": 343,\n",
      "    \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\": 896,\n",
      "    \"washer, automatic washer, washing machine\": 897,\n",
      "    \"water bottle\": 898,\n",
      "    \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\": 346,\n",
      "    \"water jug\": 899,\n",
      "    \"water ouzel, dipper\": 20,\n",
      "    \"water snake\": 58,\n",
      "    \"water tower\": 900,\n",
      "    \"weasel\": 356,\n",
      "    \"web site, website, internet site, site\": 916,\n",
      "    \"weevil\": 307,\n",
      "    \"whippet\": 172,\n",
      "    \"whiptail, whiptail lizard\": 41,\n",
      "    \"whiskey jug\": 901,\n",
      "    \"whistle\": 902,\n",
      "    \"white stork, Ciconia ciconia\": 127,\n",
      "    \"white wolf, Arctic wolf, Canis lupus tundrarum\": 270,\n",
      "    \"wig\": 903,\n",
      "    \"wild boar, boar, Sus scrofa\": 342,\n",
      "    \"window screen\": 904,\n",
      "    \"window shade\": 905,\n",
      "    \"wine bottle\": 907,\n",
      "    \"wing\": 908,\n",
      "    \"wire-haired fox terrier\": 188,\n",
      "    \"wok\": 909,\n",
      "    \"wolf spider, hunting spider\": 77,\n",
      "    \"wombat\": 106,\n",
      "    \"wood rabbit, cottontail, cottontail rabbit\": 330,\n",
      "    \"wooden spoon\": 910,\n",
      "    \"wool, woolen, woollen\": 911,\n",
      "    \"worm fence, snake fence, snake-rail fence, Virginia fence\": 912,\n",
      "    \"wreck\": 913,\n",
      "    \"yawl\": 914,\n",
      "    \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\": 986,\n",
      "    \"yurt\": 915,\n",
      "    \"zebra\": 340,\n",
      "    \"zucchini, courgette\": 939\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"layer_scale_init_value\": 1e-06,\n",
      "  \"model_type\": \"convnext\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_stages\": 4,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"patch_size\": 4,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--facebook--convnext-tiny-224\\snapshots\\6166b7613034066690a621d8bf25ffdf181a34f0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at facebook/convnext-tiny-224 were not used when initializing ConvNextModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ConvNextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ConvNextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ConvNextModel were initialized from the model checkpoint at facebook/convnext-tiny-224.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ConvNextModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 768, 7, 7]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "Error while downloading from https://cdn-lfs.hf.co/facebook/convnext-tiny-224/cccd7740d4b807d0442d17a08c0e36ddc1911aa27625b94b65b5a3cc76c94414?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1743654635&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzY1NDYzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9mYWNlYm9vay9jb252bmV4dC10aW55LTIyNC9jY2NkNzc0MGQ0YjgwN2QwNDQyZDE3YTA4YzBlMzZkZGMxOTExYWEyNzYyNWI5NGI2NWI1YTNjYzc2Yzk0NDE0P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=hOLw3VzZg28CvtmkSjQc-MAPJOncomlCKG-AYpHyrvjAVRihiEZZlfviGEEy6YhvOhuftnj9MznnH3JHQu7QZZ8su-LOKiDRhF2XFyNOeTGnwWMcLUGgApsju9k-dWQjnCbjNkLYuVvIdLeJrxsenxfR7BjRoCWRVGLK-bqafAw6uiwwu0hopV9EGDyNMJtChq22OqV8viya7BarK5%7EYQyIGS98wZ2tUJyAF9Jw1HH4nyXQ4tne46e0Yy2YoQhhLlDdJErt9e7kaL%7EfSK98NAkMWHt0LPjiN7gwRaR1lfwmsk2eEHR4hdz-i9RWZP3U-Qu1iV51RHMysQJpNrw%7E-3Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/facebook/convnext-tiny-224/cccd7740d4b807d0442d17a08c0e36ddc1911aa27625b94b65b5a3cc76c94414?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1743654635&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MzY1NDYzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9mYWNlYm9vay9jb252bmV4dC10aW55LTIyNC9jY2NkNzc0MGQ0YjgwN2QwNDQyZDE3YTA4YzBlMzZkZGMxOTExYWEyNzYyNWI5NGI2NWI1YTNjYzc2Yzk0NDE0P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=hOLw3VzZg28CvtmkSjQc-MAPJOncomlCKG-AYpHyrvjAVRihiEZZlfviGEEy6YhvOhuftnj9MznnH3JHQu7QZZ8su-LOKiDRhF2XFyNOeTGnwWMcLUGgApsju9k-dWQjnCbjNkLYuVvIdLeJrxsenxfR7BjRoCWRVGLK-bqafAw6uiwwu0hopV9EGDyNMJtChq22OqV8viya7BarK5%7EYQyIGS98wZ2tUJyAF9Jw1HH4nyXQ4tne46e0Yy2YoQhhLlDdJErt9e7kaL%7EfSK98NAkMWHt0LPjiN7gwRaR1lfwmsk2eEHR4hdz-i9RWZP3U-Qu1iV51RHMysQJpNrw%7E-3Q__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, ConvNextModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\", trust_remote_code=True)\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "model = ConvNextModel.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNextModel(\n",
      "  (embeddings): ConvNextEmbeddings(\n",
      "    (patch_embeddings): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (layernorm): ConvNextLayerNorm()\n",
      "  )\n",
      "  (encoder): ConvNextEncoder(\n",
      "    (stages): ModuleList(\n",
      "      (0): ConvNextStage(\n",
      "        (downsampling_layer): Identity()\n",
      "        (layers): Sequential(\n",
      "          (0): ConvNextLayer(\n",
      "            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNextLayer(\n",
      "            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNextLayer(\n",
      "            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ConvNextStage(\n",
      "        (downsampling_layer): Sequential(\n",
      "          (0): ConvNextLayerNorm()\n",
      "          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (layers): Sequential(\n",
      "          (0): ConvNextLayer(\n",
      "            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNextLayer(\n",
      "            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNextLayer(\n",
      "            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ConvNextStage(\n",
      "        (downsampling_layer): Sequential(\n",
      "          (0): ConvNextLayerNorm()\n",
      "          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (layers): Sequential(\n",
      "          (0): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): ConvNextLayer(\n",
      "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ConvNextStage(\n",
      "        (downsampling_layer): Sequential(\n",
      "          (0): ConvNextLayerNorm()\n",
      "          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (layers): Sequential(\n",
      "          (0): ConvNextLayer(\n",
      "            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNextLayer(\n",
      "            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNextLayer(\n",
      "            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (layernorm): ConvNextLayerNorm()\n",
      "            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUActivation()\n",
      "            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\20241\\thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\20241\\thesis\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--timm--convnextv2_tiny.fcmae. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'convnextv2_tiny.fcmae',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 768, 7, 7) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "ConvNeXt(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): ConvNeXtStage(\n",
      "      (downsample): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): GlobalResponseNormMlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (grn): GlobalResponseNorm()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_pre): Identity()\n",
      "  (head): NormMlpClassifierHead(\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (pre_logits): Identity()\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Input Embeddings Shapes\n",
      "z_i shape: torch.Size([3, 4])\n",
      "z_j shape: torch.Size([3, 4])\n",
      "\n",
      "Step 2: Normalized Embeddings\n",
      "z_i: tensor([[ 0.5615, -0.1069, -0.7939,  0.2071],\n",
      "        [-0.5424, -0.6995,  0.2017,  0.4192],\n",
      "        [-0.6956, -0.3901, -0.5770,  0.1761]])\n",
      "z_j: tensor([[-0.4860,  0.6243, -0.6076,  0.0696],\n",
      "        [-0.3013,  0.1985, -0.4746, -0.8029],\n",
      "        [ 0.1915,  0.7529,  0.4858,  0.4005]])\n",
      "\n",
      "Step 3: Concatenated Embeddings Shape: torch.Size([6, 4])\n",
      "\n",
      "Step 4: Cosine Similarity Matrix (scaled):\n",
      "tensor([[ 2.0000, -0.6063,  0.2914,  0.3144,  0.0401, -0.5515],\n",
      "        [-0.6063,  2.0000,  1.2152, -0.5331, -0.8154, -0.7293],\n",
      "        [ 0.2914,  1.2152,  2.0000,  0.9147,  0.5293, -1.2734],\n",
      "        [ 0.3144, -0.5331,  0.9147,  2.0000,  1.0056,  0.2194],\n",
      "        [ 0.0401, -0.8154,  0.5293,  1.0056,  2.0000, -0.9207],\n",
      "        [-0.5515, -0.7293, -1.2734,  0.2194, -0.9207,  2.0000]])\n",
      "\n",
      "Step 5: Similarity Matrix after Masking Self-Similarities:\n",
      "tensor([[-1.0000e+09, -6.0631e-01,  2.9138e-01,  3.1442e-01,  4.0119e-02,\n",
      "         -5.5147e-01],\n",
      "        [-6.0631e-01, -1.0000e+09,  1.2152e+00, -5.3309e-01, -8.1540e-01,\n",
      "         -7.2931e-01],\n",
      "        [ 2.9138e-01,  1.2152e+00, -1.0000e+09,  9.1475e-01,  5.2927e-01,\n",
      "         -1.2734e+00],\n",
      "        [ 3.1442e-01, -5.3309e-01,  9.1475e-01, -1.0000e+09,  1.0056e+00,\n",
      "          2.1939e-01],\n",
      "        [ 4.0119e-02, -8.1540e-01,  5.2927e-01,  1.0056e+00, -1.0000e+09,\n",
      "         -9.2074e-01],\n",
      "        [-5.5147e-01, -7.2931e-01, -1.2734e+00,  2.1939e-01, -9.2074e-01,\n",
      "         -1.0000e+09]])\n",
      "\n",
      "Step 6: Positive Similarities:\n",
      "tensor([[ 0.3144],\n",
      "        [-0.8154],\n",
      "        [-1.2734],\n",
      "        [ 0.3144],\n",
      "        [-0.8154],\n",
      "        [-1.2734]])\n",
      "\n",
      "Step 7: Negatives Shape and Values:\n",
      "Negatives shape: torch.Size([6, 5])\n",
      "tensor([[-1.0000e+09, -6.0631e-01,  2.9138e-01,  4.0119e-02, -5.5147e-01],\n",
      "        [-6.0631e-01, -1.0000e+09,  1.2152e+00, -5.3309e-01, -7.2931e-01],\n",
      "        [ 2.9138e-01,  1.2152e+00, -1.0000e+09,  9.1475e-01,  5.2927e-01],\n",
      "        [-5.3309e-01,  9.1475e-01, -1.0000e+09,  1.0056e+00,  2.1939e-01],\n",
      "        [ 4.0119e-02,  5.2927e-01,  1.0056e+00, -1.0000e+09, -9.2074e-01],\n",
      "        [-5.5147e-01, -7.2931e-01,  2.1939e-01, -9.2074e-01, -1.0000e+09]])\n",
      "\n",
      "Step 8: Logits Shape and Values:\n",
      "Logits shape: torch.Size([6, 6])\n",
      "tensor([[ 3.1442e-01, -1.0000e+09, -6.0631e-01,  2.9138e-01,  4.0119e-02,\n",
      "         -5.5147e-01],\n",
      "        [-8.1540e-01, -6.0631e-01, -1.0000e+09,  1.2152e+00, -5.3309e-01,\n",
      "         -7.2931e-01],\n",
      "        [-1.2734e+00,  2.9138e-01,  1.2152e+00, -1.0000e+09,  9.1475e-01,\n",
      "          5.2927e-01],\n",
      "        [ 3.1442e-01, -5.3309e-01,  9.1475e-01, -1.0000e+09,  1.0056e+00,\n",
      "          2.1939e-01],\n",
      "        [-8.1540e-01,  4.0119e-02,  5.2927e-01,  1.0056e+00, -1.0000e+09,\n",
      "         -9.2074e-01],\n",
      "        [-1.2734e+00, -5.5147e-01, -7.2931e-01,  2.1939e-01, -9.2074e-01,\n",
      "         -1.0000e+09]])\n",
      "\n",
      "Step 9: Labels:\n",
      "tensor([0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Step 10: Computed NT-Xent Loss: 2.3513081073760986\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NTXentLoss(torch.nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        print(\"Step 1: Input Embeddings Shapes\")\n",
    "        print(\"z_i shape:\", z_i.shape)\n",
    "        print(\"z_j shape:\", z_j.shape)\n",
    "        batch_size = z_i.shape[0]\n",
    "        \n",
    "        # Step 2: Normalize the embeddings\n",
    "        z_i = F.normalize(z_i, dim=1)\n",
    "        z_j = F.normalize(z_j, dim=1)\n",
    "        print(\"\\nStep 2: Normalized Embeddings\")\n",
    "        print(\"z_i:\", z_i)\n",
    "        print(\"z_j:\", z_j)\n",
    "        \n",
    "        # Step 3: Concatenate embeddings to form a (2N, embedding_dim) tensor\n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        print(\"\\nStep 3: Concatenated Embeddings Shape:\", z.shape)\n",
    "        \n",
    "        # Step 4: Compute the cosine similarity matrix and scale by temperature\n",
    "        sim = torch.matmul(z, z.T) / self.temperature\n",
    "        print(\"\\nStep 4: Cosine Similarity Matrix (scaled):\")\n",
    "        print(sim)\n",
    "        \n",
    "        # Step 5: Mask out self-similarities by replacing the diagonal with a very low value\n",
    "        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "        sim.masked_fill_(mask, -1e9)\n",
    "        print(\"\\nStep 5: Similarity Matrix after Masking Self-Similarities:\")\n",
    "        print(sim)\n",
    "        \n",
    "        # Step 6: Identify the positive indices for each sample.\n",
    "        # For sample i, its positive is at index (i + batch_size) % (2N)\n",
    "        positive_indices = (torch.arange(2 * batch_size, device=z.device) + batch_size) % (2 * batch_size)\n",
    "        positives = sim[torch.arange(2 * batch_size), positive_indices].unsqueeze(1)\n",
    "        print(\"\\nStep 6: Positive Similarities:\")\n",
    "        print(positives)\n",
    "        \n",
    "        # Step 7: Extract negatives by removing the positive column.\n",
    "        all_indices = torch.arange(2 * batch_size, device=z.device).unsqueeze(0).expand(2 * batch_size, -1)\n",
    "        pos_indices = positive_indices.unsqueeze(1)\n",
    "        neg_mask = all_indices != pos_indices\n",
    "        negatives = sim[neg_mask].view(2 * batch_size, -1)\n",
    "        print(\"\\nStep 7: Negatives Shape and Values:\")\n",
    "        print(\"Negatives shape:\", negatives.shape)\n",
    "        print(negatives)\n",
    "        \n",
    "        # Step 8: Construct logits by concatenating positives and negatives.\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        print(\"\\nStep 8: Logits Shape and Values:\")\n",
    "        print(\"Logits shape:\", logits.shape)\n",
    "        print(logits)\n",
    "        \n",
    "        # Step 9: Create labels; for each sample, the positive is the first element.\n",
    "        labels = torch.zeros(2 * batch_size, dtype=torch.long, device=z.device)\n",
    "        print(\"\\nStep 9: Labels:\")\n",
    "        print(labels)\n",
    "        \n",
    "        # Step 10: Compute cross-entropy loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        print(\"\\nStep 10: Computed NT-Xent Loss:\", loss.item())\n",
    "        return loss\n",
    "\n",
    "# Example usage with dummy data for clarity\n",
    "if __name__ == \"__main__\":\n",
    "    # Create random dummy embeddings for a batch of 4 samples with embedding dimension of 128\n",
    "    batch_size = 3\n",
    "    embedding_dim = 4\n",
    "    torch.manual_seed(0)\n",
    "    z_i = torch.randn(batch_size, embedding_dim)\n",
    "    z_j = torch.randn(batch_size, embedding_dim)\n",
    "    \n",
    "    loss_fn = NTXentLoss(temperature=0.5)\n",
    "    loss = loss_fn(z_i, z_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571\n",
      "Precision: 0.8333\n",
      "Recall: 0.9091\n",
      "F1-Score: 0.8696\n",
      "False Positive Rate (FPR): 0.2000\n",
      "False Negative Rate (FNR): 0.0909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_metrics(tp, tn, fp, fn):\n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    \n",
    "    # Recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    \n",
    "    # F1-Score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    \n",
    "    # False Positive Rate (FPR)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "    \n",
    "    # False Negative Rate (FNR)\n",
    "    fnr = fn / (fn + tp) if (fn + tp) != 0 else 0\n",
    "    \n",
    "    # ROC-AUC (This requires probability scores, not just TP, TN, FP, FN. For simplicity, assume you have them)\n",
    "    # Assuming `y_true` as actual labels and `y_scores` as predicted probabilities\n",
    "    # y_true = [1, 0, 1, 0, ...]\n",
    "    # y_scores = [0.9, 0.1, 0.8, 0.3, ...]\n",
    "    # roc_auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    # ROC-AUC would need actual values for predictions and probabilities (not just TP, TN, FP, FN)\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'False Positive Rate (FPR)': fpr,\n",
    "        'False Negative Rate (FNR)': fnr\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "tp = 50\n",
    "tn = 40\n",
    "fp = 10\n",
    "fn = 5\n",
    "\n",
    "metrics = evaluate_metrics(tp, tn, fp, fn)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): EmbeddingHead(\n",
      "    (embedding): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Remove the original head\n",
    "\n",
    "\n",
    "# Add embedding projection layer\n",
    "class EmbeddingHead(nn.Module):\n",
    "    def __init__(self, in_features=768, embedding_dim=512, normalize=True, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.normalize_output = normalize\n",
    "        self.embedding = nn.Linear(in_features, embedding_dim)\n",
    "        self.bn = nn.BatchNorm1d(embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        if self.normalize_output:\n",
    "            x = nn.functional.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "\n",
    "# Replace the head with embedding layer\n",
    "model.fc = EmbeddingHead(in_features=2048, embedding_dim=256)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define image transforms (same as DINO training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Load sample image\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "img = Image.open(urlopen(url))\n",
    "\n",
    "# Preprocess image\n",
    "img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "# Get model output\n",
    "with torch.no_grad():\n",
    "    features = model(img_tensor)\n",
    "\n",
    "print(\"Output shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(32, 32), stride=(32, 32))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (patch_drop): Identity()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): EmbeddingHead(\n",
      "    (embedding): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\20241\\thesis\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--timm--vit_small_patch32_224.augreg_in21k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# Load ViT model from timm\n",
    "model = timm.create_model('timm/vit_small_patch32_224.augreg_in21k_ft_in1k', pretrained=True)\n",
    "\n",
    "# Replace head with embedding layer\n",
    "model.head = EmbeddingHead(in_features=384, embedding_dim=256)\n",
    "model.eval()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define image transforms (same as DINO training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Load sample image\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "img = Image.open(urlopen(url))\n",
    "\n",
    "# Preprocess image\n",
    "img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "# Get model output\n",
    "with torch.no_grad():\n",
    "    features = model(img_tensor)\n",
    "\n",
    "print(\"Output shape:\", features.squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 49,165,818\n",
      "Model size in MB: 187.55 MB\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "print(f\"Model size in MB: {total_params * 4 / (1024 * 1024):.2f} MB\")  # Assuming float32 (4 bytes per parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
