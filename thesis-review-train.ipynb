{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T04:43:19.742841Z",
     "iopub.status.busy": "2025-04-02T04:43:19.742486Z",
     "iopub.status.idle": "2025-04-02T04:43:19.747960Z",
     "shell.execute_reply": "2025-04-02T04:43:19.747147Z",
     "shell.execute_reply.started": "2025-04-02T04:43:19.742803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T04:43:19.749491Z",
     "iopub.status.busy": "2025-04-02T04:43:19.749203Z",
     "iopub.status.idle": "2025-04-02T04:43:22.815787Z",
     "shell.execute_reply": "2025-04-02T04:43:22.815074Z",
     "shell.execute_reply.started": "2025-04-02T04:43:19.749462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "def is_image_file(file_path):\n",
    "    # Common image file extensions\n",
    "    image_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\", \".webp\"]\n",
    "    # Get file extension\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    return ext in image_extensions\n",
    "\n",
    "\n",
    "def is_valid_part_format(s):\n",
    "    # Define the pattern\n",
    "    pattern = r\"^part([1-9]|1[0-4])$\"\n",
    "    # Match the string against the pattern\n",
    "    match = re.match(pattern, s)\n",
    "    return bool(match)\n",
    "\n",
    "\n",
    "class TripletDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        transform=None,\n",
    "        sample_negatives=\"epoch\",\n",
    "        limit=-1,\n",
    "        neg_only_reviews=True,\n",
    "        type='train'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        root_dir: Path to dataset (folders as classes)\n",
    "        transform: Image transformations (e.g., augmentation, normalization)\n",
    "        sample_negatives:\n",
    "            - \"batch\" → Selects a random negative for each sample dynamically.\n",
    "            - \"epoch\" → Assigns a negative at the start of each epoch.\n",
    "            - \"fixed\" → Precomputed negative samples from a CSV file.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.sample_negatives = sample_negatives\n",
    "        self.neg_only_reviews = neg_only_reviews\n",
    "\n",
    "        self.class_to_images = defaultdict(list)  # { class: [image1, image2, ...] }\n",
    "        self.samples = []  # [(anchor_path, positive_path, class)]\n",
    "\n",
    "        # Read dataset structure\n",
    "        for part_folder in os.listdir(root_dir):\n",
    "            if self.__len__() >= limit and limit > 0:\n",
    "                break\n",
    "            if type == 'train':\n",
    "                part_path = os.path.join(root_dir, part_folder, part_folder)\n",
    "            else:\n",
    "                part_path = os.path.join(root_dir, part_folder)\n",
    "            print(part_path)\n",
    "            if not os.path.isdir(part_path) or not is_valid_part_format(part_folder):\n",
    "                continue\n",
    "            for product_folder in os.listdir(part_path):\n",
    "                if self.__len__() >= limit and limit > 0:\n",
    "                    break\n",
    "\n",
    "                product_path = os.path.join(part_path, product_folder)\n",
    "                if os.path.isdir(product_path):\n",
    "                    product_and_review = [\n",
    "                        os.path.join(product_path, img)\n",
    "                        for img in os.listdir(product_path)\n",
    "                    ]\n",
    "                    if (\n",
    "                        len(product_and_review) < 2\n",
    "                    ):  # Ensure at least an anchor-positive pair\n",
    "                        continue\n",
    "\n",
    "                    positive = None\n",
    "                    anchor = None\n",
    "                    for i in product_and_review:\n",
    "                        if os.path.isdir(i):  # review\n",
    "                            reviews = [\n",
    "                                os.path.join(i, review_img)\n",
    "                                for review_img in os.listdir(i)\n",
    "                            ]\n",
    "                            if len(reviews) == 0:\n",
    "                                continue\n",
    "                            # Get only first review image if it have multiple reivews\n",
    "                            valid_review_imgs = [\n",
    "                                file for file in reviews if is_image_file(file)\n",
    "                            ]\n",
    "                            if len(valid_review_imgs) > 0:\n",
    "                                positive = valid_review_imgs[0]\n",
    "                        elif is_image_file(i) and anchor is None:\n",
    "                            anchor = i\n",
    "\n",
    "                        if positive is not None and anchor is not None:\n",
    "                            self.class_to_images[product_folder] = [\n",
    "                                anchor,\n",
    "                                positive,\n",
    "                            ]\n",
    "                            self.samples.append(\n",
    "                                (anchor, positive, product_folder)\n",
    "                            )  # Anchor & positive\n",
    "                            continue\n",
    "\n",
    "        # Precompute negatives if needed\n",
    "        if self.sample_negatives == \"epoch\":\n",
    "            self.negative_map = self.assign_negatives()\n",
    "\n",
    "    def assign_negatives(self):\n",
    "        \"\"\"Assigns a random negative from a different class at the start of each epoch.\"\"\"\n",
    "        negative_map = {}\n",
    "        product_list = list(self.class_to_images.keys())\n",
    "\n",
    "        for product_label in self.class_to_images:\n",
    "            neg_reviews = [cls for cls in product_list if cls != product_label]\n",
    "            neg_review = random.choice(neg_reviews)\n",
    "            if not self.neg_only_reviews:\n",
    "                negative_map[product_label] = random.choice(\n",
    "                    self.class_to_images[neg_review]\n",
    "                )\n",
    "            else:\n",
    "                negative_map[product_label] = self.class_to_images[neg_review][1]\n",
    "\n",
    "        return negative_map\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_path, positive_path, product_label = self.samples[index]\n",
    "\n",
    "        # Choose negative based on sampling strategy\n",
    "        if self.sample_negatives == \"batch\":\n",
    "            neg_reviews = [\n",
    "                cls for cls in self.class_to_images.keys() if cls != product_label\n",
    "            ]\n",
    "            neg_review = random.choice(neg_reviews)\n",
    "            negative_path = random.choice(self.class_to_images[neg_review])\n",
    "        elif self.sample_negatives == \"epoch\":\n",
    "            negative_path = self.negative_map[product_label]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported sampling strategy. Use 'batch' or 'epoch'.\")\n",
    "\n",
    "        # Load images\n",
    "        anchor = Image.open(anchor_path).convert(\"RGB\")\n",
    "        positive = Image.open(positive_path).convert(\"RGB\")\n",
    "        negative = Image.open(negative_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def update_negatives(self):\n",
    "        \"\"\"Call this at the start of each epoch if using 'epoch' sampling.\"\"\"\n",
    "        if self.sample_negatives == \"epoch\":\n",
    "            self.negative_map = self.assign_negatives()\n",
    "\n",
    "\n",
    "class EvalTripletDataset(TripletDataset):\n",
    "\n",
    "    def assign_negatives(self):\n",
    "        \"\"\"\n",
    "        Gán các mẫu âm (negative samples) cho từng sản phẩm.\n",
    "\n",
    "        Mô tả:\n",
    "        - Duyệt qua danh sách các sản phẩm (`class_to_images`).\n",
    "        - Mỗi sản phẩm được gán với một sản phẩm khác làm mẫu âm (negative).\n",
    "        - Sử dụng kỹ thuật xoay vòng (circular indexing) để đảm bảo mỗi sản phẩm có một mẫu âm hợp lệ.\n",
    "\n",
    "        Returns:\n",
    "            dict: Bản đồ ánh xạ từ sản phẩm gốc sang mẫu âm.\n",
    "        \"\"\"\n",
    "        negative_map = {}\n",
    "        product_list = list(self.class_to_images.keys())\n",
    "        total_products = len(product_list)\n",
    "\n",
    "        for idx, product_label in enumerate(self.class_to_images):\n",
    "            next_idx = (idx + 1) % total_products  # Xoay vòng danh sách\n",
    "            neg_reviews = product_list[next_idx]\n",
    "            negative_map[product_label] = self.class_to_images[neg_reviews][1]\n",
    "\n",
    "        return negative_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_batch(anchor, pos, neg, threshold=0.5, metric=\"l2\"):\n",
    "    \"\"\"\n",
    "    Đánh giá theo batch với metric là cosine similarity hoặc L2 distance.\n",
    "\n",
    "    Args:\n",
    "        anchor (torch.Tensor): Batch embedding của anchor, shape (batch_size, embedding_dim)\n",
    "        pos (torch.Tensor): Batch embedding của positive, shape (batch_size, embedding_dim)\n",
    "        neg (torch.Tensor): Batch embedding của negative, shape (batch_size, embedding_dim)\n",
    "        threshold (float): Ngưỡng quyết định mẫu có giống nhau không.\n",
    "        metric (str): 'cosine' hoặc 'l2' để chọn phương pháp đo khoảng cách.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (TP, TN, FP, FN)\n",
    "    \"\"\"\n",
    "\n",
    "    if metric == \"cosine\":\n",
    "        # Tính cosine similarity\n",
    "        sim_pos = F.cosine_similarity(\n",
    "            anchor, pos, dim=-1\n",
    "        )  # Cosine similarity giữa anchor và positive\n",
    "        sim_neg = F.cosine_similarity(\n",
    "            anchor, neg, dim=-1\n",
    "        )  # Cosine similarity giữa anchor và negative\n",
    "\n",
    "        # Xác định TP, FP, TN, FN\n",
    "        tp = (sim_pos >= threshold).sum().item()  # Dự đoán đúng positive\n",
    "        fn = (\n",
    "            (sim_pos < threshold).sum().item()\n",
    "        )  # Dự đoán sai positive (đáng lẽ giống nhưng bị xem là khác)\n",
    "        tn = (sim_neg < threshold).sum().item()  # Dự đoán đúng negative\n",
    "        fp = (\n",
    "            (sim_neg >= threshold).sum().item()\n",
    "        )  # Dự đoán sai negative (đáng lẽ khác nhưng bị xem là giống)\n",
    "\n",
    "    elif metric == \"l2\":\n",
    "        # Tính L2 distance\n",
    "        dist_pos = torch.norm(\n",
    "            anchor - pos, p=2, dim=-1\n",
    "        )  # Khoảng cách L2 giữa anchor và positive\n",
    "        dist_neg = torch.norm(\n",
    "            anchor - neg, p=2, dim=-1\n",
    "        )  # Khoảng cách L2 giữa anchor và negative\n",
    "\n",
    "        # Xác định TP, FP, TN, FN\n",
    "        tp = (dist_pos <= threshold).sum().item()  # Dự đoán đúng positive\n",
    "        fn = (dist_pos > threshold).sum().item()  # Dự đoán sai positive\n",
    "        tn = (dist_neg > threshold).sum().item()  # Dự đoán đúng negative\n",
    "        fp = (dist_neg <= threshold).sum().item()  # Dự đoán sai negative\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Metric must be 'cosine' or 'l2'\")\n",
    "\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "def evaluate_metrics(tp, tn, fp, fn):\n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "\n",
    "    # Recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "\n",
    "    # F1-Score\n",
    "    f1_score = (\n",
    "        2 * (precision * recall) / (precision + recall)\n",
    "        if (precision + recall) != 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    # False Positive Rate (FPR)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "\n",
    "    # False Negative Rate (FNR)\n",
    "    fnr = fn / (fn + tp) if (fn + tp) != 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1_score,\n",
    "        \"False Positive Rate (FPR)\": fpr,\n",
    "        \"False Negative Rate (FNR)\": fnr,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T04:43:22.817575Z",
     "iopub.status.busy": "2025-04-02T04:43:22.817202Z",
     "iopub.status.idle": "2025-04-02T04:43:27.214283Z",
     "shell.execute_reply": "2025-04-02T04:43:27.213631Z",
     "shell.execute_reply.started": "2025-04-02T04:43:22.817551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from typing import Literal\n",
    "from eval import evaluate_batch, evaluate_metrics\n",
    "\n",
    "\n",
    "class SpamDetectorTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        criterion: torch.nn.Module,\n",
    "        train_loader: torch.utils.data.DataLoader,\n",
    "        valid_loader: torch.utils.data.DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler=None,\n",
    "        lr_types: Literal[\"step\", \"epoch\"] = \"step\",\n",
    "        device: torch.device = \"cuda\",\n",
    "        epochs: int = 10,\n",
    "        max_norm: float = 0,\n",
    "        log_writer: wandb = None,\n",
    "        patience=3,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.lr_types = lr_types\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.max_norm = max_norm\n",
    "        self.log_writer = log_writer\n",
    "        self.patience = patience\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        global_step = epoch * len(self.train_loader)  # Global step tracking🔥\n",
    "\n",
    "        for step, (anchor, positive, negative) in enumerate(self.train_loader):\n",
    "            anchor, positive, negative = (\n",
    "                anchor.to(self.device),\n",
    "                positive.to(self.device),\n",
    "                negative.to(self.device),\n",
    "            )\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            anchor_embeded = self.model(anchor)\n",
    "            positive_embeded = self.model(positive)\n",
    "            negative_embeded = self.model(negative)\n",
    "            loss = self.criterion(anchor_embeded, positive_embeded, negative_embeded)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Tính toán Gradient Norm\n",
    "            total_norm = 0\n",
    "            param_count = 0\n",
    "\n",
    "            for param in self.model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param_norm = param.grad.norm().item()\n",
    "                    total_norm += param_norm\n",
    "                    param_count += 1\n",
    "\n",
    "            mean_grad_norm = total_norm / param_count if param_count > 0 else 0\n",
    "\n",
    "            # Áp dụng Gradient Clipping nếu cần\n",
    "            if self.max_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_norm)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Step scheduler per step\n",
    "            if self.scheduler and self.lr_types == \"step\":\n",
    "                self.scheduler.step()\n",
    "\n",
    "            # Log to W&B\n",
    "            if self.log_writer:\n",
    "                self.log_writer.log(\n",
    "                    {\n",
    "                        \"train/loss\": loss.item(),\n",
    "                        \"train/learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n",
    "                        \"train/grad_norm\": mean_grad_norm,\n",
    "                        \"train/global_step\": global_step + step,\n",
    "                        \"train/epoch\": epoch + step / len(self.train_loader),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        epoch_loss = total_loss / len(self.train_loader)\n",
    "        if self.log_writer:\n",
    "            self.log_writer.log({\"train/mean_loss\": epoch_loss})\n",
    "\n",
    "        # Step scheduler per epoch\n",
    "        if self.scheduler and self.lr_types == \"epoch\":\n",
    "            self.scheduler.step()  # Step based on epoch\n",
    "\n",
    "        return epoch_loss\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for step, (anchor, positive, negative) in enumerate(self.valid_loader):\n",
    "                anchor, positive, negative = (\n",
    "                    anchor.to(self.device),\n",
    "                    positive.to(self.device),\n",
    "                    negative.to(self.device),\n",
    "                )\n",
    "                anchor_embeded = self.model(anchor)\n",
    "                positive_embeded = self.model(positive)\n",
    "                negative_embeded = self.model(negative)\n",
    "                loss = self.criterion(\n",
    "                    anchor_embeded, positive_embeded, negative_embeded\n",
    "                )\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                eval_step_result = evaluate_batch(\n",
    "                    anchor_embeded, positive_embeded, negative_embeded\n",
    "                )\n",
    "                tp += eval_step_result[0]\n",
    "                tn += eval_step_result[1]\n",
    "                fp += eval_step_result[2]\n",
    "                fn += eval_step_result[3]\n",
    "\n",
    "        metrics = evaluate_metrics(tp, tn, fp, fn)\n",
    "\n",
    "        # Calculate average loss\n",
    "        avg_loss = running_loss / len(self.valid_loader)\n",
    "\n",
    "        # Log metrics and loss to W&B\n",
    "        if self.log_writer:\n",
    "            # Log evaluation metrics\n",
    "            self.log_writer.log(\n",
    "                {\n",
    "                    \"val/accuracy\": metrics[\"Accuracy\"],\n",
    "                    \"val/precision\": metrics[\"Precision\"],\n",
    "                    \"val/recall\": metrics[\"Recall\"],\n",
    "                    \"val/f1_score\": metrics[\"F1-Score\"],\n",
    "                    \"val/False Positive Rate\": metrics[\"False Positive Rate (FPR)\"],\n",
    "                    \"val/False Negative Rate\": metrics[\"False Negative Rate (FNR)\"],\n",
    "                    \"val/val_loss\": avg_loss,\n",
    "                }\n",
    "            )\n",
    "        return avg_loss\n",
    "\n",
    "    def train(self, resume_from_checkpoint=None):\n",
    "        start_epoch = 0\n",
    "        best_val_loss = float(\"inf\")\n",
    "        epochs_without_improvement = 0  # Track epochs without improvement\n",
    "\n",
    "        # Load checkpoint if provided\n",
    "        if resume_from_checkpoint:\n",
    "            checkpoint = torch.load(resume_from_checkpoint, map_location=self.device)\n",
    "            self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "            if \"scheduler_state_dict\" in checkpoint and self.scheduler:\n",
    "                self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "\n",
    "            start_epoch = checkpoint[\"epoch\"] + 1\n",
    "            best_val_loss = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
    "            epochs_without_improvement = checkpoint.get(\"epochs_without_improvement\", 0)\n",
    "\n",
    "            print(f\"Resuming training from epoch {start_epoch}\")\n",
    "        else:\n",
    "            print(\"Start training!\")\n",
    "        for epoch in range(start_epoch, start_epoch + self.epochs):\n",
    "            epoch_loss = self.train_one_epoch(epoch)\n",
    "            val_loss = self.validate()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{self.epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Check if validation loss improved\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_without_improvement = 0  # Reset counter\n",
    "                print(\n",
    "                    f\"New best validation loss: {best_val_loss:.4f}. Saving checkpoint.\"\n",
    "                )\n",
    "\n",
    "                checkpoint = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": (\n",
    "                        self.scheduler.state_dict() if self.scheduler else None\n",
    "                    ),\n",
    "                    \"best_val_loss\": best_val_loss,\n",
    "                    \"epochs_without_improvement\": epochs_without_improvement,\n",
    "                }\n",
    "                torch.save(checkpoint, f\"checkpoint_{epoch}.pth\")\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                print(\n",
    "                    f\"No improvement for {epochs_without_improvement}/{self.patience} epochs.\"\n",
    "                )\n",
    "\n",
    "            # Stop training if no improvement for `self.patience` epochs\n",
    "            if epochs_without_improvement >= self.patience:\n",
    "                print(\n",
    "                    f\"Validation loss hasn't improved for {self.patience} epochs. Stopping training early.\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "        print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T04:43:27.215692Z",
     "iopub.status.busy": "2025-04-02T04:43:27.215294Z",
     "iopub.status.idle": "2025-04-02T04:43:27.220732Z",
     "shell.execute_reply": "2025-04-02T04:43:27.219827Z",
     "shell.execute_reply.started": "2025-04-02T04:43:27.215639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class EmbeddingHead(nn.Module):\n",
    "    def __init__(self, embedding_size, in_features, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.batchnorm = nn.BatchNorm2d(in_features)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(in_features, embedding_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # Output: (N, embedding_size)\n",
    "        return nn.functional.normalize(x, dim=-1)  # Chuẩn hóa theo chiều feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T04:43:27.222036Z",
     "iopub.status.busy": "2025-04-02T04:43:27.221742Z",
     "iopub.status.idle": "2025-04-02T04:44:18.418479Z",
     "shell.execute_reply": "2025-04-02T04:44:18.417640Z",
     "shell.execute_reply.started": "2025-04-02T04:43:27.222006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch\n",
    "from torchvision.models import ConvNeXt_Tiny_Weights, convnext_tiny\n",
    "import wandb\n",
    "\n",
    "data_path = \"/kaggle/input/review-thesis-datasets\"\n",
    "val_data_path = \"/kaggle/input/val-review-thesis-datasets\"\n",
    "# Hyperparameters\n",
    "base_lr = 2e-5  # Learning rate ban đầu\n",
    "num_epochs = 50\n",
    "dataset_size = 5000\n",
    "val_dataset_size = 1000\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1  # 10% epochs đầu là warmup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = convnext_tiny(weight=ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "model.classifier = EmbeddingHead(128, 768)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "old_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize tất cả ảnh về 224x224\n",
    "        transforms.ToTensor(),  # Chuyển ảnh thành tensor\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Lật ngang ảnh với xác suất 50%\n",
    "        transforms.ColorJitter(brightness=0.3),  # Điều chỉnh độ sáng (±30%)\n",
    "        transforms.RandomPerspective(\n",
    "            distortion_scale=0.5, p=0.5\n",
    "        ),  # Biến dạng phối cảnh\n",
    "        transforms.RandomRotation(degrees=30),  # Xoay ảnh trong khoảng ±30 độ\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize tất cả ảnh về 224x224\n",
    "        transforms.ToTensor(),  # Chuyển ảnh thành tensor\n",
    "        transforms.ColorJitter(brightness=0.3),  # Điều chỉnh độ sáng (±30%)\n",
    "        transforms.RandomPerspective(\n",
    "            distortion_scale=0.5, p=0.5\n",
    "        ),  # Biến dạng phối cảnh\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize tất cả ảnh về 224x224\n",
    "        transforms.ToTensor(),  # Chuyển ảnh thành tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('Load train datasets!')\n",
    "dataset = TripletDataset(data_path, transform=transform, limit=dataset_size)\n",
    "print('Load val datasets!')\n",
    "val_dataset = EvalTripletDataset(val_data_path, transform=val_transform, limit=val_dataset_size, type='val')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Khởi tạo Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
    "criterion = torch.nn.TripletMarginLoss()\n",
    "lr_scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=base_lr,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=int(dataset_size / batch_size),\n",
    "    pct_start=warmup_ratio\n",
    ")\n",
    "\n",
    "# Lặp qua dataloader để lấy batch\n",
    "for images, labels, negative in train_loader:\n",
    "    print(\n",
    "        f\"Batch size: {images.shape}, Labels: {labels.shape}, Negative: {negative.shape}\"\n",
    "    )\n",
    "    break  # Dừng sau batch đầu tiên\n",
    "\n",
    "for images, labels, negative in val_loader:\n",
    "    print(\n",
    "        f\"Batch size: {images.shape}, Labels: {labels.shape}, Negative: {negative.shape}\"\n",
    "    )\n",
    "    break  # Dừng sau batch đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-02T04:45:33.804Z",
     "iopub.execute_input": "2025-04-02T04:44:18.419721Z",
     "iopub.status.busy": "2025-04-02T04:44:18.419386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.login(key=\"c436a4917c43e09e30b67b919bd06e7bf7b0c10d\")\n",
    "wandb.init(project=\"review thesis project\", name=\"experiment_8\")\n",
    "# wandb.init(project=\"review thesis project\", name=\"experiment_2\", resume=\"allow\")\n",
    "torch.cuda.empty_cache()\n",
    "trainer = SpamDetectorTrainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    device=device,\n",
    "    epochs=num_epochs,\n",
    "    log_writer=wandb,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6998594,
     "sourceId": 11208284,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7000694,
     "sourceId": 11211479,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
